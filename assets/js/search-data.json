{
  
    
        "post0": {
            "title": "Overview of artifact & noise detection",
            "content": "from IPython.display import YouTubeVideo YouTubeVideo(&#39;lcux-Fj-IYE&#39;, width=700, height=700) . %matplotlib inline . import os import numpy as np import mne sample_data_folder = mne.datasets.sample.data_path() sample_data_raw_file = os.path.join(sample_data_folder, &#39;MEG&#39;, &#39;sample&#39;, &#39;sample_audvis_raw.fif&#39;) raw = mne.io.read_raw_fif(sample_data_raw_file) raw.crop(0, 60).load_data() # just use a fraction of data for speed here . Opening raw data file C: Users babib mne_data MNE-sample-data MEG sample sample_audvis_raw.fif... Read a total of 3 projection items: PCA-v1 (1 x 102) idle PCA-v2 (1 x 102) idle PCA-v3 (1 x 102) idle Range : 25800 ... 192599 = 42.956 ... 320.670 secs Ready. Current compensation grade : 0 Reading 0 ... 36037 = 0.000 ... 60.000 secs... . &lt;Raw | sample_audvis_raw.fif, 376 x 36038 (60.0 s), ~107.0 MB, data loaded&gt; . What are artifacts? . Environmental artifacts . Persistent oscillations centered around the AC power line frequency_ (typically 50 or 60 Hz) | Brief signal jumps due to building vibration (such as a door slamming) | Electromagnetic field noise from nearby elevators, cell phones, the geomagnetic field, etc. | . | Instrumentation artifacts . Electromagnetic interference from stimulus presentation (such as EEG sensors picking up the field generated by unshielded headphones) | Continuous oscillations at specific frequencies used by head position indicator (HPI) coils | Random high-amplitude fluctuations (or alternatively, constant zero signal) in a single channel due to sensor malfunction (e.g., in surface electrodes, poor scalp contact) | . | Biological artifacts . Periodic QRS_-like signal patterns (especially in magnetometer channels) due to electrical activity of the heart | Short step-like deflections (especially in frontal EEG channels) due to eye movements | Large transient deflections (especially in frontal EEG channels) due to blinking | Brief bursts of high frequency fluctuations across several channels due to the muscular activity during swallowing | . | . Note . Artifacts of the same genesis may appear different in recordings made by different EEG or MEG systems, due to differences in sensor design (e.g., passive vs. active EEG electrodes; axial vs. planar gradiometers, etc). . What to do about artifacts . There are 3 basic options when faced with artifacts in your recordings: . Ignore the artifact and carry on with analysis | Exclude the corrupted portion of the data and analyze the remaining data | Repair the artifact by suppressing artifactual part of the recording while (hopefully) leaving the signal of interest intact | Artifact detection . MNE-Python includes a few tools for automated detection of certain artifacts (such as heartbeats and blinks), but of course you can always visually inspect your data to identify and annotate artifacts as well. . Low-frequency drifts . mag_channels = mne.pick_types(raw.info, meg=&#39;mag&#39;) raw.plot(duration=60, order=mag_channels, n_channels=len(mag_channels),remove_dc=False); . Power line noise . Power line artifacts are easiest to see on plots of the spectrum, so we&#39;ll use :meth:~mne.io.Raw.plot_psd to illustrate. . fig = raw.plot_psd(tmax=np.inf, fmax=250, average=True) # add some arrows at 60 Hz and its harmonics: for ax in fig.axes[:2]: freqs = ax.lines[-1].get_xdata() psds = ax.lines[-1].get_ydata() for freq in (60, 120, 180, 240): idx = np.searchsorted(freqs, freq) ax.arrow(x=freqs[idx], y=psds[idx] + 18, dx=0, dy=-12, color=&#39;red&#39;, width=0.1, head_width=3, length_includes_head=True) . Effective window size : 3.410 (s) Effective window size : 3.410 (s) Effective window size : 3.410 (s) . Heartbeat artifacts (ECG) . ecg_epochs = mne.preprocessing.create_ecg_epochs(raw) ecg_epochs.plot_image(combine=&#39;mean&#39;) . Reconstructing ECG signal from Magnetometers Setting up band-pass filter from 8 - 16 Hz FIR filter parameters Designing a two-pass forward and reverse, zero-phase, non-causal bandpass filter: - Windowed frequency-domain design (firwin2) method - Hann window - Lower passband edge: 8.00 - Lower transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 7.75 Hz) - Upper passband edge: 16.00 Hz - Upper transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 16.25 Hz) - Filter length: 8192 samples (13.639 sec) Number of ECG events detected : 59 (average pulse 58 / min.) 59 matching events found No baseline correction applied Not setting metadata Created an SSP operator (subspace dimension = 3) Loading data for 59 events and 601 original time points ... 0 bad epochs dropped 59 matching events found No baseline correction applied Not setting metadata 0 projection items activated 0 bad epochs dropped 59 matching events found No baseline correction applied Not setting metadata 0 projection items activated 0 bad epochs dropped 59 matching events found No baseline correction applied Not setting metadata 0 projection items activated 0 bad epochs dropped combining channels using &#34;mean&#34; combining channels using &#34;mean&#34; combining channels using &#34;mean&#34; . [&lt;Figure size 432x288 with 3 Axes&gt;, &lt;Figure size 432x288 with 3 Axes&gt;, &lt;Figure size 432x288 with 3 Axes&gt;] . The horizontal streaks in the magnetometer image plot reflect the fact that the heartbeat artifacts are superimposed on low-frequency drifts like the one we saw in an earlier section; to avoid this you could pass baseline=(-0.5, -0.2) in the call to :func:~mne.preprocessing.create_ecg_epochs. You can also get a quick look at the ECG-related field pattern across sensors by averaging the ECG epochs together via the :meth:~mne.Epochs.average method, and then using the :meth:mne.Evoked.plot_topomap method: . avg_ecg_epochs = ecg_epochs.average() . Here again we can visualize the spatial pattern of the associated field at various times relative to the peak of the EOG response: . avg_ecg_epochs.plot_topomap(times=np.linspace(-0.05, 0.05, 11)) . Or, we can get an ERP/F plot with :meth:~mne.Evoked.plot or a combined scalp field maps and ERP/F plot with :meth:~mne.Evoked.plot_joint. Here we&#39;ve specified the times for scalp field maps manually, but if not provided they will be chosen automatically based on peaks in the signal: . avg_ecg_epochs.plot_joint(times=[-0.25, -0.025, 0, 0.025, 0.25]); . Ocular artifacts (EOG) . eog_epochs = mne.preprocessing.create_eog_epochs(raw, baseline=(-0.5, -0.2)) eog_epochs.plot_image(combine=&#39;mean&#39;) eog_epochs.average().plot_joint() . EOG channel index for this subject is: [375] Filtering the data to remove DC offset to help distinguish blinks from saccades Setting up band-pass filter from 1 - 10 Hz FIR filter parameters Designing a two-pass forward and reverse, zero-phase, non-causal bandpass filter: - Windowed frequency-domain design (firwin2) method - Hann window - Lower passband edge: 1.00 - Lower transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 0.75 Hz) - Upper passband edge: 10.00 Hz - Upper transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 10.25 Hz) - Filter length: 8192 samples (13.639 sec) Now detecting blinks and generating corresponding events Found 10 significant peaks Number of EOG events detected : 10 10 matching events found Applying baseline correction (mode: mean) Not setting metadata Created an SSP operator (subspace dimension = 3) Loading data for 10 events and 601 original time points ... 0 bad epochs dropped 10 matching events found No baseline correction applied Not setting metadata 0 projection items activated 0 bad epochs dropped 10 matching events found No baseline correction applied Not setting metadata 0 projection items activated 0 bad epochs dropped 10 matching events found No baseline correction applied Not setting metadata 0 projection items activated 0 bad epochs dropped combining channels using &#34;mean&#34; combining channels using &#34;mean&#34; combining channels using &#34;mean&#34; . [&lt;Figure size 576x302.4 with 7 Axes&gt;, &lt;Figure size 576x302.4 with 7 Axes&gt;, &lt;Figure size 576x302.4 with 7 Axes&gt;] . Summary . Familiarizing yourself with typical artifact patterns and magnitudes is a crucial first step in assessing the efficacy of later attempts to repair those artifacts. A good rule of thumb is that the artifact amplitudes should be orders of magnitude larger than your signal of interest — and there should be several occurrences of such events — in order to find signal decompositions that effectively estimate and repair the artifacts. . Several other tutorials in this section illustrate the various tools for artifact repair, and discuss the pros and cons of each technique, for example: . tut-artifact-ssp | tut-artifact-ica | tut-artifact-sss | . There are also tutorials on general-purpose preprocessing steps such as filtering and resampling &lt;tut-filter-resample&gt; and excluding bad channels &lt;tut-bad-channels&gt; or `spans of data . `.&lt;/p&gt; .. LINKS . https://en.wikipedia.org/wiki/Mains_electricity . &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; %matplotlib inline . Filtering and resampling data . import mne from mne.datasets import sample data_path = sample.data_path() raw_fname = data_path + &#39;/MEG/sample/sample_audvis_raw.fif&#39; . Setup for reading the raw data (save memory by cropping the raw data before loading it) . tmin, tmax = 0, 20 # use the first 20s of data raw = mne.io.read_raw_fif(raw_fname) raw.crop(tmin, tmax).load_data() raw.info[&#39;bads&#39;] = [&#39;MEG 2443&#39;, &#39;EEG 053&#39;] # bads + 2 more . Opening raw data file C: Users babib mne_data MNE-sample-data/MEG/sample/sample_audvis_raw.fif... Read a total of 3 projection items: PCA-v1 (1 x 102) idle PCA-v2 (1 x 102) idle PCA-v3 (1 x 102) idle Range : 25800 ... 192599 = 42.956 ... 320.670 secs Ready. Current compensation grade : 0 Reading 0 ... 12012 = 0.000 ... 20.000 secs... . Pick a subset of channels (here for speed reason) . selection = mne.read_selection(&#39;Left-temporal&#39;) picks = mne.pick_types(raw.info, meg=&#39;mag&#39;, eeg=False, eog=False, stim=False, exclude=&#39;bads&#39;, selection=selection) . Let&#39;s first check out all channel types . raw.plot_psd(area_mode=&#39;range&#39;, tmax=10.0, picks=picks, average=False); . Effective window size : 3.410 (s) . Removing power-line noise with notch filtering . Removing power-line noise can be done with a Notch filter, directly on the Raw object, specifying an array of frequency to be cut off: . import numpy as np raw.notch_filter(np.arange(60, 241, 60), picks=picks, filter_length=&#39;auto&#39;, phase=&#39;zero&#39;) raw.plot_psd(area_mode=&#39;range&#39;, tmax=10.0, picks=picks, average=False); . Setting up band-stop filter FIR filter parameters Designing a one-pass, zero-phase, non-causal bandstop filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower transition bandwidth: 0.50 Hz - Upper transition bandwidth: 0.50 Hz - Filter length: 3965 samples (6.602 sec) Effective window size : 3.410 (s) . Removing power-line noise with low-pass filtering . If you&#39;re only interested in low frequencies, below the peaks of power-line noise you can simply low pass filter the data. . raw.filter(None, 50., fir_design=&#39;firwin&#39;) raw.plot_psd(area_mode=&#39;range&#39;, tmax=10.0, picks=picks, average=False); . Filtering raw data in 1 contiguous segment Setting up low-pass filter at 50 Hz FIR filter parameters Designing a one-pass, zero-phase, non-causal lowpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Upper passband edge: 50.00 Hz - Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz) - Filter length: 159 samples (0.265 sec) Effective window size : 3.410 (s) . High-pass filtering to remove slow drifts . To remove slow drifts, you can high pass. . raw.filter(1., None, fir_design=&#39;firwin&#39;) raw.plot_psd(area_mode=&#39;range&#39;, tmax=10.0, picks=picks, average=False); . Filtering raw data in 1 contiguous segment Setting up high-pass filter at 1 Hz FIR filter parameters Designing a one-pass, zero-phase, non-causal highpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 1.00 - Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz) - Filter length: 1983 samples (3.302 sec) Effective window size : 3.410 (s) . To do the low-pass and high-pass filtering in one step you can do a so-called band-pass filter by running the following: . raw.filter(1, 50., fir_design=&#39;firwin&#39;) . Filtering raw data in 1 contiguous segment Setting up band-pass filter from 1 - 50 Hz l_trans_bandwidth chosen to be 1.0 Hz h_trans_bandwidth chosen to be 12.5 Hz Filter length of 1983 samples (3.302 sec) selected . &lt;Raw | sample_audvis_raw.fif, n_channels x n_times : 376 x 12013 (20.0 sec), ~38.1 MB, data loaded&gt; . raw.plot(); . Downsampling and decimation . Data resampling can be done with resample methods. . raw.resample(100, npad=&quot;auto&quot;) # set sampling frequency to 100Hz raw.plot_psd(area_mode=&#39;range&#39;, tmax=10.0, picks=picks); . 25 events found Event IDs: [ 1 2 3 4 5 32] 25 events found Event IDs: [ 1 2 3 4 5 32] Effective window size : 10.010 (s) . raw.plot(); . Warning: This will reduce the timing precision of events . To avoid this reduction in precision, the suggested pipeline for processing final data to be analyzed is: . low-pass the data with mne.io.Raw.filter. | Extract epochs with mne.Epochs. | Decimate the Epochs object using mne.Epochs.decimate or the decim argument to the mne.Epochs object. | We also provide the convenience methods mne.Epochs.resample and mne.Evoked.resample to downsample or upsample data, but these are less optimal because they will introduce edge artifacts into every epoch, whereas filtering the raw data will only introduce edge artifacts only at the start and end of the recording. . Marking bad channels . If you already know which are the bad channels, simply do: . raw.info[&#39;bads&#39;] = [&#39;MEG 2443&#39;] . You can also mark them interactively in raw.plot(). The bad channel is shown in gray . ch_names = raw.info[&#39;ch_names&#39;].copy() ch_names.remove(&#39;MEG 2443&#39;) raw.reorder_channels([&#39;MEG 2443&#39;] + ch_names) raw.plot(); . It&#39;s not only raw. You can mark bads also in evoked. Let&#39;s first read in the evoked data. . # Reading data with a bad channel marked as bad: fname = data_path + &#39;/MEG/sample/sample_audvis-ave.fif&#39; evoked = mne.read_evokeds(fname, condition=&#39;Left Auditory&#39;, baseline=(None, 0)) evoked.pick_types(meg=&#39;grad&#39;, eeg=False, exclude=[]) # plot with bads evoked.plot(exclude=[], time_unit=&#39;s&#39;); . Reading C: Users babib mne_data MNE-sample-data/MEG/sample/sample_audvis-ave.fif ... Read a total of 4 projection items: PCA-v1 (1 x 102) active PCA-v2 (1 x 102) active PCA-v3 (1 x 102) active Average EEG reference (1 x 60) active Found the data of interest: t = -199.80 ... 499.49 ms (Left Auditory) 0 CTF compensation matrices available nave = 55 - aspect type = 100 Projections have already been applied. Setting proj attribute to True. Applying baseline correction (mode: mean) . It&#39;s also possible to repair the bad channels using interpolation . evoked.interpolate_bads(reset_bads=False, verbose=False); . Let’s plot the cleaned data . evoked.plot(exclude=[], time_unit=&#39;s&#39;); . Marking bad epochs . MNE allows you to specify rejection dictionary based on peak-to-peak thresholds for each channel type . reject = dict(grad=4000e-13, mag=4e-12, eog=200e-6) . events = mne.find_events(raw, stim_channel=&#39;STI 014&#39;) event_id = {&quot;auditory/left&quot;: 1} tmin, tmax = -0.2, 0.5 baseline = (None, 0) # means from the first instant to t = 0 picks = mne.pick_types(raw.info, meg=True, eeg=True, eog=True, stim=False, exclude=&#39;bads&#39;) epochs = mne.Epochs(raw, events, event_id, tmin, tmax, proj=True, picks=picks, baseline=baseline, reject=reject, preload=True) . 25 events found Event IDs: [ 1 2 3 4 5 32] 6 matching events found Applying baseline correction (mode: mean) Not setting metadata Created an SSP operator (subspace dimension = 3) 3 projection items activated Loading data for 6 events and 71 original time points ... 0 bad epochs dropped . You can also reject after constructing epochs, just do: . reject.update({&#39;eog&#39;: 150e-6}) epochs.drop_bad(reject=reject) . 0 bad epochs dropped . &lt;Epochs | 6 events (all good), -0.2 - 0.5 sec, baseline [None, 0], ~4.8 MB, data loaded, &#39;auditory/left&#39;: 6&gt; . But the thresholds need to be stricter each time. . Tuning rejection thresholds . import matplotlib.pyplot as plt from ipywidgets import interact picks = mne.pick_types(raw.info, meg=False, eeg=True) epochs = mne.Epochs(raw, events, event_id, tmin, tmax, proj=True, picks=picks, baseline=baseline, reject=None, preload=True) def reject_epochs(reject): reject = dict(eeg=reject * 1e-6) evoked = epochs.copy().drop_bad(reject=reject, verbose=False).average() evoked.plot(spatial_colors=True) print(&#39;Number of epochs retained: %d/%d&#39; % (evoked.nave, len(epochs))) . 6 matching events found Applying baseline correction (mode: mean) Not setting metadata 3 projection items activated Loading data for 6 events and 71 original time points ... 0 bad epochs dropped . interact(reject_epochs, reject=(35, 250, 10)); . Number of epochs retained: 6/6 . Autoreject . Autoreject (global) can compute the rejection dictionary automatically . http://autoreject.github.io/ . from autoreject import get_rejection_threshold # noqa reject = get_rejection_threshold(epochs) print(reject) . Estimating rejection dictionary for eeg {&#39;eeg&#39;: 5.2068012537220574e-05} . Autoreject (local) finds per channel thresholds: . . import numpy as np from autoreject import AutoReject n_interpolates = np.array([1, 2, 4]) consensus = np.linspace(0.5, 1.0, 6) ar = AutoReject(n_interpolates, consensus, thresh_method=&#39;random_search&#39;, random_state=42) . Now, we find the rejection thresholds per-channel and optimize for the number of channels to be interpolated. . raw.info[&#39;bads&#39;] = [] picks = mne.pick_types(raw.info, meg=&#39;grad&#39;, eeg=False) epochs = mne.Epochs(raw, events, event_id, tmin, tmax, proj=True, picks=picks, baseline=baseline, reject=None, preload=True) # Note that fitting and transforming can be done on different compatible # portions of data if needed. ar.fit(epochs) . 6 matching events found Applying baseline correction (mode: mean) Not setting metadata 3 projection items activated Loading data for 6 events and 71 original time points ... 0 bad epochs dropped . Now, we can look at the rejection thresholds for each channel . for ch_name in epochs.info[&#39;ch_names&#39;][:5]: print(&#39;%s: %s&#39; % (ch_name, ar.threshes_[ch_name])) # plt.hist(np.array(list(ar.threshes_.values())), 30, color=&#39;g&#39;, alpha=0.4) . We can check what applying autoreject would do to the epochs: . Good data (light red) | Bad segment but not to be interpolated (medium dark red) | Bad segment to be interpolated (dark red) | . reject_log = ar.get_reject_log(epochs[&#39;auditory/left&#39;]) reject_log.plot() . Another way to visualize this is to plot them on the epochs . reject_log.plot_epochs(epochs[&#39;auditory/left&#39;]); . We can apply these rejection thresholds to new (or to the old) data: . epochs_clean = ar.transform(epochs[&#39;auditory/left&#39;]) . evoked = epochs[&#39;auditory/left&#39;].average() evoked.info[&#39;bads&#39;] = [&#39;MEG 2443&#39;] evoked.plot(exclude=[]); evoked_clean = epochs_clean.average() evoked_clean.info[&#39;bads&#39;] = [&#39;MEG 2443&#39;] evoked_clean.plot(exclude=[]); . For more info, visit . http://autoreject.github.io/ . &lt;/div&gt; .",
            "url": "https://berdakh.github.io/blog/eeg/mne/jupyter/2020/09/22/MNE-Overview-Of-Artifact.html",
            "relUrl": "/eeg/mne/jupyter/2020/09/22/MNE-Overview-Of-Artifact.html",
            "date": " • Sep 22, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "MNE tutorial part 2",
            "content": "from IPython.display import YouTubeVideo YouTubeVideo(&#39;wNIaT1UT6rI&#39;, width=800, height=400) . %matplotlib inline import mne import matplotlib.pyplot as plt . fname = &quot;oddball-epo.fif&quot; . epochs = mne.read_epochs(fname) . Reading oddball-epo.fif ... Isotrak not found Found the data of interest: t = -200.00 ... 500.00 ms 0 CTF compensation matrices available 212 matching events found Applying baseline correction (mode: mean) Not setting metadata 0 projection items activated . epochs . &lt;EpochsFIF | 212 events (all good), -0.2 - 0.5 sec, baseline [-0.2, 0], ~7.5 MB, data loaded, &#39;standard/stimulus&#39;: 106 &#39;target/stimulus&#39;: 106&gt; . epochs.get_data().shape . (212, 64, 71) . Evoked . Finally, if we average an epoched dataset over trials, we can use the mne.Evoked object. . target = epochs[&quot;target&quot;].average() target . &lt;Evoked | &#39;target/stimulus&#39; (average, N=106), [-0.2, 0.5] sec, 63 ch, ~153 kB&gt; . standard = epochs[&quot;standard&quot;].average() . epochs[].get_data().shape . (212, 64, 71) . epochs[&#39;target&#39;].get_data().shape . (106, 64, 71) . target.data.shape . (63, 71) . target.info . &lt;Info | 10 non-empty values bads: [] ch_names: FP1, FP2, F7, F3, Fz, F4, F8, FC5, FC1, FC2, FC6, T7, C3, Cz, ... chs: 63 EEG custom_ref_applied: True file_id: 4 items (dict) highpass: 1.0 Hz lowpass: 20.0 Hz meas_date: 2017-08-10 20:05:16 UTC meas_id: 4 items (dict) nchan: 63 projs: [] sfreq: 100.0 Hz &gt; . To quickly investigate evoked activity, the Evoked object has a number of plotting functions available. . target.info[&#39;ch_names&#39;] . [&#39;FP1&#39;, &#39;FP2&#39;, &#39;F7&#39;, &#39;F3&#39;, &#39;Fz&#39;, &#39;F4&#39;, &#39;F8&#39;, &#39;FC5&#39;, &#39;FC1&#39;, &#39;FC2&#39;, &#39;FC6&#39;, &#39;T7&#39;, &#39;C3&#39;, &#39;Cz&#39;, &#39;C4&#39;, &#39;T8&#39;, &#39;CP5&#39;, &#39;CP1&#39;, &#39;CP2&#39;, &#39;CP6&#39;, &#39;P7&#39;, &#39;P3&#39;, &#39;Pz&#39;, &#39;P4&#39;, &#39;P8&#39;, &#39;PO9&#39;, &#39;O1&#39;, &#39;Oz&#39;, &#39;O2&#39;, &#39;PO10&#39;, &#39;AF7&#39;, &#39;AF3&#39;, &#39;AF4&#39;, &#39;AF8&#39;, &#39;F5&#39;, &#39;F1&#39;, &#39;F2&#39;, &#39;F6&#39;, &#39;SO1&#39;, &#39;FT7&#39;, &#39;FC3&#39;, &#39;FC4&#39;, &#39;FT8&#39;, &#39;SO2&#39;, &#39;C5&#39;, &#39;C1&#39;, &#39;C2&#39;, &#39;C6&#39;, &#39;TP7&#39;, &#39;CP3&#39;, &#39;CPz&#39;, &#39;CP4&#39;, &#39;TP8&#39;, &#39;P5&#39;, &#39;P1&#39;, &#39;P2&#39;, &#39;P6&#39;, &#39;PO7&#39;, &#39;PO3&#39;, &#39;POz&#39;, &#39;PO4&#39;, &#39;PO8&#39;, &#39;FCz&#39;] . dir(target) . [&#39;__class__&#39;, &#39;__contains__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__ne__&#39;, &#39;__neg__&#39;, &#39;__new__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__slotnames__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;, &#39;_aspect_kind&#39;, &#39;_data&#39;, &#39;_get_channel_positions&#39;, &#39;_pick_drop_channels&#39;, &#39;_projector&#39;, &#39;_set_channel_positions&#39;, &#39;_size&#39;, &#39;_update_first_last&#39;, &#39;add_channels&#39;, &#39;add_proj&#39;, &#39;animate_topomap&#39;, &#39;anonymize&#39;, &#39;apply_baseline&#39;, &#39;apply_hilbert&#39;, &#39;apply_proj&#39;, &#39;as_type&#39;, &#39;ch_names&#39;, &#39;comment&#39;, &#39;compensation_grade&#39;, &#39;copy&#39;, &#39;crop&#39;, &#39;data&#39;, &#39;decimate&#39;, &#39;del_proj&#39;, &#39;detrend&#39;, &#39;drop_channels&#39;, &#39;filter&#39;, &#39;first&#39;, &#39;get_channel_types&#39;, &#39;get_peak&#39;, &#39;info&#39;, &#39;interpolate_bads&#39;, &#39;kind&#39;, &#39;last&#39;, &#39;nave&#39;, &#39;pick&#39;, &#39;pick_channels&#39;, &#39;pick_types&#39;, &#39;picks&#39;, &#39;plot&#39;, &#39;plot_field&#39;, &#39;plot_image&#39;, &#39;plot_joint&#39;, &#39;plot_projs_topomap&#39;, &#39;plot_sensors&#39;, &#39;plot_topo&#39;, &#39;plot_topomap&#39;, &#39;plot_white&#39;, &#39;preload&#39;, &#39;proj&#39;, &#39;rename_channels&#39;, &#39;reorder_channels&#39;, &#39;resample&#39;, &#39;save&#39;, &#39;savgol_filter&#39;, &#39;set_channel_types&#39;, &#39;set_eeg_reference&#39;, &#39;set_meas_date&#39;, &#39;set_montage&#39;, &#39;shift_time&#39;, &#39;time_as_index&#39;, &#39;times&#39;, &#39;to_data_frame&#39;, &#39;verbose&#39;] . &#39;plot&#39;, &#39;plot_field&#39;, &#39;plot_image&#39;, &#39;plot_joint&#39;, &#39;plot_projs_topomap&#39;, &#39;plot_sensors&#39;, &#39;plot_topo&#39;, &#39;plot_topomap&#39;, &#39;plot_white&#39;, Visualization . target.plot(); . target.plot_topomap? . Signature: target.plot_topomap( times=&#39;auto&#39;, ch_type=None, layout=None, vmin=None, vmax=None, cmap=None, sensors=True, colorbar=True, scalings=None, units=None, res=64, size=1, cbar_fmt=&#39;%3.1f&#39;, time_unit=&#39;s&#39;, time_format=None, proj=False, show=True, show_names=False, title=None, mask=None, mask_params=None, outlines=&#39;head&#39;, contours=6, image_interp=&#39;bilinear&#39;, average=None, head_pos=None, axes=None, extrapolate=&#39;box&#39;, sphere=None, border=0, nrows=1, ncols=&#39;auto&#39;, ) Docstring: Plot topographic maps of specific time points of evoked data. Parameters - times : float | array of float | &#34;auto&#34; | &#34;peaks&#34; | &#34;interactive&#34; The time point(s) to plot. If &#34;auto&#34;, the number of ``axes`` determines the amount of time point(s). If ``axes`` is also None, at most 10 topographies will be shown with a regular time spacing between the first and last time instant. If &#34;peaks&#34;, finds time points automatically by checking for local maxima in global field power. If &#34;interactive&#34;, the time can be set interactively at run-time by using a slider. ch_type : &#39;mag&#39; | &#39;grad&#39; | &#39;planar1&#39; | &#39;planar2&#39; | &#39;eeg&#39; | None The channel type to plot. For &#39;grad&#39;, the gradiometers are collected in pairs and the RMS for each pair is plotted. If None, then channels are chosen in the order given above. layout : None Deprecated and will be removed in 0.21. Use ``sphere`` to control head-sensor relationship instead. vmin : float | callable | None The value specifying the lower bound of the color range. If None, and vmax is None, -vmax is used. Else np.min(data). If callable, the output equals vmin(data). Defaults to None. vmax : float | callable | None The value specifying the upper bound of the color range. If None, the maximum absolute value is used. If callable, the output equals vmax(data). Defaults to None. cmap : matplotlib colormap | (colormap, bool) | &#39;interactive&#39; | None Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range (zoom). The mouse scroll can also be used to adjust the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None (default), &#39;Reds&#39; is used for all positive data, otherwise defaults to &#39;RdBu_r&#39;. If &#39;interactive&#39;, translates to (None, True). .. warning:: Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps. sensors : bool | str Add markers for sensor locations to the plot. Accepts matplotlib plot format string (e.g., &#39;r+&#39; for red plusses). If True (default), circles will be used. colorbar : bool | None Plot a colorbar in the rightmost column of the figure. None (default) is the same as True, but emits a warning if custom ``axes`` are provided to remind the user that the colorbar will occupy the last :class:`matplotlib.axes.Axes` instance. scalings : dict | float | None The scalings of the channel types to be applied for plotting. If None, defaults to ``dict(eeg=1e6, grad=1e13, mag=1e15)``. units : dict | str | None The unit of the channel type used for colorbar label. If scale is None the unit is automatically determined. res : int The resolution of the topomap image (n pixels along each side). size : float Side length per topomap in inches. cbar_fmt : str String format for colorbar values. time_unit : str The units for the time axis, can be &#34;ms&#34; or &#34;s&#34; (default). .. versionadded:: 0.16 time_format : str | None String format for topomap values. Defaults (None) to &#34;%01d ms&#34; if ``time_unit=&#39;ms&#39;``, &#34;%0.3f s&#34; if ``time_unit=&#39;s&#39;``, and &#34;%g&#34; otherwise. proj : bool | &#39;interactive&#39; If true SSP projections are applied before display. If &#39;interactive&#39;, a check box for reversible selection of SSP projection vectors will be show. show : bool Show figure if True. show_names : bool | callable If True, show channel names on top of the map. If a callable is passed, channel names will be formatted using the callable; e.g., to delete the prefix &#39;MEG &#39; from all channel names, pass the function lambda x: x.replace(&#39;MEG &#39;, &#39;&#39;). If `mask` is not None, only significant sensors will be shown. title : str | None Title. If None (default), no title is displayed. mask : ndarray of bool, shape (n_channels, n_times) | None The channels to be marked as significant at a given time point. Indices set to `True` will be considered. Defaults to None. mask_params : dict | None Additional plotting parameters for plotting significant sensors. Default (None) equals:: dict(marker=&#39;o&#39;, markerfacecolor=&#39;w&#39;, markeredgecolor=&#39;k&#39;, linewidth=0, markersize=4) outlines : &#39;head&#39; | &#39;skirt&#39; | dict | None The outlines to be drawn. If &#39;head&#39;, the default head scheme will be drawn. If &#39;skirt&#39; the head scheme will be drawn, but sensors are allowed to be plotted outside of the head circle. If dict, each key refers to a tuple of x and y positions, the values in &#39;mask_pos&#39; will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to &#39;head&#39;. contours : int | array of float The number of contour lines to draw. If 0, no contours will be drawn. When an integer, matplotlib ticker locator is used to find suitable values for the contour thresholds (may sometimes be inaccurate, use array for accuracy). If an array, the values represent the levels for the contours. The values are in µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the ticks in colorbar correspond to the contour levels. Defaults to 6. image_interp : str The image interpolation to be used. All matplotlib options are accepted. average : float | None The time window around a given time to be used for averaging (seconds). For example, 0.01 would translate into window that starts 5 ms before and ends 5 ms after a given time point. Defaults to None, which means no averaging. head_pos : dict | None Deprecated and will be removed in 0.21. Use ``sphere`` instead. axes : instance of Axes | list | None The axes to plot to. If list, the list must be a list of Axes of the same length as ``times`` (unless ``times`` is None). If instance of Axes, ``times`` must be a float or a list of one float. Defaults to None. extrapolate : str Options: - &#39;box&#39; (default) Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension. - &#39;local&#39; Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). - &#39;head&#39; Extrapolate to the edges of the head circle (does not work well with sensors outside the head circle). .. versionadded:: 0.18 sphere : float | array-like | str | None The sphere parameters to use for the cartoon head. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give the radius (origin assumed 0, 0, 0). Can also be a spherical ConductorModel, which will use the origin and radius. Can be &#34;auto&#34; to use a digitization-based fit. Can also be None (default) to use &#39;auto&#39; when enough extra digitization points are available, and 0.095 otherwise. Currently the head radius does not affect plotting. .. versionadded:: 0.20 border : float | &#39;mean&#39; Value to extrapolate to on the topomap borders. If ``&#39;mean&#39;`` then each extrapolated point has the average value of its neighbours. .. versionadded:: 0.20 nrows : int | &#39;auto&#39; The number of rows of topographies to plot. Defaults to 1. If &#39;auto&#39;, obtains the number of rows depending on the amount of times to plot and the number of cols. Not valid when times == &#39;interactive&#39;. .. versionadded:: 0.20 ncols : int | &#39;auto&#39; The number of columns of topographies to plot. If &#39;auto&#39; (default), obtains the number of columns depending on the amount of times to plot and the number of rows. Not valid when times == &#39;interactive&#39;. .. versionadded:: 0.20 Returns - fig : instance of matplotlib.figure.Figure The figure. File: c: users babib anaconda3 envs mne lib site-packages mne evoked.py Type: method . Plot Topomap . target.plot_topomap(times = [0.1, 0.2, 0.3, 0.4, 0.5]); . target.plot_joint(times = [0.1, 0.2, 0.3, 0.37, 0.5]); . For condition contrasts, you can use mne.combine.evoked: . mne.combine_evoked? . Signature: mne.combine_evoked(all_evoked, weights) Docstring: Merge evoked data by weighted addition or subtraction. Data should have the same channels and the same time instants. Subtraction can be performed by calling ``combine_evoked([evoked1, -evoked2], &#39;equal&#39;)`` .. Warning:: If you provide an array of weights instead of using `&#39;equal&#39;` or `&#39;nave&#39;`, strange things may happen with your resulting signal amplitude and/or `.nave` attribute. Parameters - all_evoked : list of Evoked The evoked datasets. weights : list of float | str The weights to apply to the data of each evoked instance. Can also be ``&#39;nave&#39;`` to weight according to evoked.nave, or ``&#34;equal&#34;`` to use equal weighting (each weighted as ``1/N``). Returns - evoked : Evoked The new evoked data. Notes -- .. versionadded:: 0.9.0 File: c: users babib anaconda3 envs mne lib site-packages mne evoked.py Type: function . Plot Joint . diff = mne.combine_evoked((target, -standard), weights=&#39;equal&#39;) diff.plot_joint(times=[0.1, 0.2, 0.3, 0.37, 0.5]); . Or as an image: . diff.plot_image(); . Because we have a 10/20 electrode layout, we can easily use a somewhat nicer layout: . rois = mne.channels.make_1020_channel_selections(diff.info, midline=&quot;z12&quot;) . rois . {&#39;Left&#39;: array([25, 57, 58, 20, 53, 21, 48, 16, 49, 12, 44, 11, 40, 7, 39, 3, 34, 2, 31, 30]), &#39;Midline&#39;: array([27, 28, 26, 59, 54, 55, 22, 17, 18, 50, 46, 13, 45, 62, 9, 8, 4, 36, 35, 1, 0, 38, 43]), &#39;Right&#39;: array([29, 61, 60, 24, 56, 23, 52, 19, 51, 14, 15, 47, 41, 10, 42, 5, 37, 6, 32, 33])} . Plot Image by the Region of Interest . diff.plot_image(group_by=rois, show=False, show_names=&quot;all&quot;); . To contrast multiple conditions, mne.viz.plot_compare_evokeds is available: . mne.viz.plot_compare_evokeds({&quot;standard&quot;: standard, &quot;target&quot;: target}, picks=[9]); . &#39;plot&#39;, &#39;plot_field&#39;, &#39;plot_image&#39;, &#39;plot_joint&#39;, &#39;plot_projs_topomap&#39;, &#39;plot_sensors&#39;, &#39;plot_topo&#39;, &#39;plot_topomap&#39;, &#39;plot_white&#39;, target.plot_topo(); . target.plot_sensors(show_names = True); . target.data . array([[-2.10035784e-07, -2.76375979e-07, -4.35090469e-07, ..., -3.15511555e-06, -2.78982956e-06, -2.65591278e-06], [-1.14376608e-06, -1.12506920e-06, -1.19371126e-06, ..., -6.47561653e-06, -6.07672040e-06, -5.82352233e-06], [ 5.98786497e-07, 3.52630830e-07, 2.33978080e-07, ..., -9.69141043e-07, -8.53105041e-07, -9.22077181e-07], ..., [-4.99535795e-08, 3.00249622e-07, 3.81435930e-07, ..., 2.44255774e-06, 1.95231303e-06, 1.41322678e-06], [-3.46014338e-08, 1.47143539e-07, 2.53983361e-07, ..., 1.59443108e-06, 1.11796711e-06, 7.14063649e-07], [-1.44211725e-06, -1.33997168e-06, -1.55426496e-06, ..., -6.17147388e-06, -5.47561990e-06, -5.17723397e-06]]) . x = target.data . ch_names = target.info[&#39;ch_names&#39;] ch_names . [&#39;FP1&#39;, &#39;FP2&#39;, &#39;F7&#39;, &#39;F3&#39;, &#39;Fz&#39;, &#39;F4&#39;, &#39;F8&#39;, &#39;FC5&#39;, &#39;FC1&#39;, &#39;FC2&#39;, &#39;FC6&#39;, &#39;T7&#39;, &#39;C3&#39;, &#39;Cz&#39;, &#39;C4&#39;, &#39;T8&#39;, &#39;CP5&#39;, &#39;CP1&#39;, &#39;CP2&#39;, &#39;CP6&#39;, &#39;P7&#39;, &#39;P3&#39;, &#39;Pz&#39;, &#39;P4&#39;, &#39;P8&#39;, &#39;PO9&#39;, &#39;O1&#39;, &#39;Oz&#39;, &#39;O2&#39;, &#39;PO10&#39;, &#39;AF7&#39;, &#39;AF3&#39;, &#39;AF4&#39;, &#39;AF8&#39;, &#39;F5&#39;, &#39;F1&#39;, &#39;F2&#39;, &#39;F6&#39;, &#39;SO1&#39;, &#39;FT7&#39;, &#39;FC3&#39;, &#39;FC4&#39;, &#39;FT8&#39;, &#39;SO2&#39;, &#39;C5&#39;, &#39;C1&#39;, &#39;C2&#39;, &#39;C6&#39;, &#39;TP7&#39;, &#39;CP3&#39;, &#39;CPz&#39;, &#39;CP4&#39;, &#39;TP8&#39;, &#39;P5&#39;, &#39;P1&#39;, &#39;P2&#39;, &#39;P6&#39;, &#39;PO7&#39;, &#39;PO3&#39;, &#39;POz&#39;, &#39;PO4&#39;, &#39;PO8&#39;, &#39;FCz&#39;] . channel = &#39;Cz&#39; chIndex = [i for i, j in enumerate(ch_names) if j == channel] . plt.plot(x.T) plt.title(channel) plt.ylabel(&quot;Amplitude&quot;) plt.xlabel(&#39;Time Samples&#39;) . Text(0.5, 0, &#39;Time Samples&#39;) . Time-Frequency stuff . For an overview over the spectral shape of the data, we can use a plotting method of raw, raw.plot_psd: . epochs_for_tfr = mne.read_epochs(&quot;oddball-long-epo.fif&quot;) . Reading oddball-long-epo.fif ... Isotrak not found Found the data of interest: t = -500.00 ... 1500.00 ms 0 CTF compensation matrices available 212 matching events found Applying baseline correction (mode: mean) Not setting metadata 0 projection items activated . plot_psd . epochs_for_tfr.plot_psd? . Signature: epochs_for_tfr.plot_psd( fmin=0, fmax=inf, tmin=None, tmax=None, proj=False, bandwidth=None, adaptive=False, low_bias=True, normalization=&#39;length&#39;, picks=None, ax=None, color=&#39;black&#39;, xscale=&#39;linear&#39;, area_mode=&#39;std&#39;, area_alpha=0.33, dB=True, estimate=&#39;auto&#39;, show=True, n_jobs=1, average=False, line_alpha=None, spatial_colors=True, sphere=None, verbose=None, ) Docstring: Plot the power spectral density across channels. Different channel types are drawn in sub-plots. When the data have been processed with a bandpass, lowpass or highpass filter, dashed lines indicate the boundaries of the filter (--). The line noise frequency is also indicated with a dashed line (-.). Parameters - fmin : float Start frequency to consider. fmax : float End frequency to consider. tmin : float | None Start time to consider. tmax : float | None End time to consider. proj : bool Apply projection. bandwidth : float The bandwidth of the multi taper windowing function in Hz. The default value is a window half-bandwidth of 4. adaptive : bool Use adaptive weights to combine the tapered spectra into PSD (slow, use n_jobs &gt;&gt; 1 to speed up computation). low_bias : bool Only use tapers with more than 90% spectral concentration within bandwidth. normalization : str Either &#34;full&#34; or &#34;length&#34; (default). If &#34;full&#34;, the PSD will be normalized by the sampling rate as well as the length of the signal (as in nitime). picks : str | list | slice | None Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel *type* strings (e.g., ``[&#39;meg&#39;, &#39;eeg&#39;]``) will pick channels of those types, channel *name* strings (e.g., ``[&#39;MEG0111&#39;, &#39;MEG2623&#39;]`` will pick the given channels. Can also be the string values &#34;all&#34; to pick all channels, or &#34;data&#34; to pick :term:`data channels`. None (default) will pick good data channels Cannot be None if `ax` is supplied.If both `picks` and `ax` are None separate subplots will be created for each standard channel type (`mag`, `grad`, and `eeg`). ax : instance of Axes | None Axes to plot into. If None, axes will be created. color : str | tuple A matplotlib-compatible color to use. Has no effect when spatial_colors=True. xscale : str Can be &#39;linear&#39; (default) or &#39;log&#39;. area_mode : str | None Mode for plotting area. If &#39;std&#39;, the mean +/- 1 STD (across channels) will be plotted. If &#39;range&#39;, the min and max (across channels) will be plotted. Bad channels will be excluded from these calculations. If None, no area will be plotted. If average=False, no area is plotted. area_alpha : float Alpha for the area. dB : bool Plot Power Spectral Density (PSD), in units (amplitude**2/Hz (dB)) if ``dB=True``, and ``estimate=&#39;power&#39;`` or ``estimate=&#39;auto&#39;``. Plot PSD in units (amplitude**2/Hz) if ``dB=False`` and, ``estimate=&#39;power&#39;``. Plot Amplitude Spectral Density (ASD), in units (amplitude/sqrt(Hz)), if ``dB=False`` and ``estimate=&#39;amplitude&#39;`` or ``estimate=&#39;auto&#39;``. Plot ASD, in units (amplitude/sqrt(Hz) (db)), if ``dB=True`` and ``estimate=&#39;amplitude&#39;``. estimate : str, {&#39;auto&#39;, &#39;power&#39;, &#39;amplitude&#39;} Can be &#34;power&#34; for power spectral density (PSD), &#34;amplitude&#34; for amplitude spectrum density (ASD), or &#34;auto&#34; (default), which uses &#34;power&#34; when dB is True and &#34;amplitude&#34; otherwise. show : bool Show figure if True. n_jobs : int The number of jobs to run in parallel (default 1). Requires the joblib package. average : bool If False, the PSDs of all channels is displayed. No averaging is done and parameters area_mode and area_alpha are ignored. When False, it is possible to paint an area (hold left mouse button and drag) to plot a topomap. line_alpha : float | None Alpha for the PSD line. Can be None (default) to use 1.0 when ``average=True`` and 0.1 when ``average=False``. spatial_colors : bool Whether to use spatial colors. Only used when ``average=False``. sphere : float | array-like | str | None The sphere parameters to use for the cartoon head. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give the radius (origin assumed 0, 0, 0). Can also be a spherical ConductorModel, which will use the origin and radius. Can be &#34;auto&#34; to use a digitization-based fit. Can also be None (default) to use &#39;auto&#39; when enough extra digitization points are available, and 0.095 otherwise. Currently the head radius does not affect plotting. .. versionadded:: 0.20 verbose : bool, str, int, or None If not None, override default verbose level (see :func:`mne.verbose` and :ref:`Logging documentation &lt;tut_logging&gt;` for more). Returns - fig : instance of Figure Figure with frequency spectra of the data channels. File: c: users babib anaconda3 envs mne lib site-packages mne epochs.py Type: method . epochs_for_tfr.info . &lt;Info | 10 non-empty values bads: [] ch_names: FP1, FP2, F7, F3, Fz, F4, F8, FC5, FC1, FC2, FC6, T7, C3, Cz, ... chs: 63 EEG, 1 STIM custom_ref_applied: True file_id: 4 items (dict) highpass: 1.0 Hz lowpass: 20.0 Hz meas_date: 2017-08-10 20:05:16 UTC meas_id: 4 items (dict) nchan: 64 projs: [] sfreq: 100.0 Hz &gt; . epochs_for_tfr.plot_psd(fmin=0, fmax=40); . Using multitaper spectrum estimation with 7 DPSS windows . But what about the time/frequency correlates of the Oddball effect? . We will extract power per time and frequency with Morlet wavelets. . from mne.time_frequency import tfr_morlet . mne.time_frequency.tfr_morlet? . Signature: mne.time_frequency.tfr_morlet( inst, freqs, n_cycles, use_fft=False, return_itc=True, decim=1, n_jobs=1, picks=None, zero_mean=True, average=True, output=&#39;power&#39;, verbose=None, ) Docstring: Compute Time-Frequency Representation (TFR) using Morlet wavelets. Parameters - inst : Epochs | Evoked The epochs or evoked object. freqs : ndarray, shape (n_freqs,) The frequencies in Hz. n_cycles : float | ndarray, shape (n_freqs,) The number of cycles globally or for each frequency. use_fft : bool, default False The fft based convolution or not. return_itc : bool, default True Return inter-trial coherence (ITC) as well as averaged power. Must be ``False`` for evoked data. decim : int | slice, default 1 To reduce memory usage, decimation factor after time-frequency decomposition. If `int`, returns tfr[..., ::decim]. If `slice`, returns tfr[..., decim]. .. note:: Decimation may create aliasing artifacts. n_jobs : int The number of jobs to run in parallel (default 1). Requires the joblib package. picks : array-like of int | None, default None The indices of the channels to decompose. If None, all available good data channels are decomposed. zero_mean : bool, default True Make sure the wavelet has a mean of zero. .. versionadded:: 0.13.0 average : bool, default True If True average across Epochs. .. versionadded:: 0.13.0 output : str Can be &#34;power&#34; (default) or &#34;complex&#34;. If &#34;complex&#34;, then average must be False. .. versionadded:: 0.15.0 verbose : bool, str, int, or None If not None, override default verbose level (see :func:`mne.verbose` and :ref:`Logging documentation &lt;tut_logging&gt;` for more). Returns - power : AverageTFR | EpochsTFR The averaged or single-trial power. itc : AverageTFR | EpochsTFR The inter-trial coherence (ITC). Only returned if return_itc is True. See Also -- mne.time_frequency.tfr_array_morlet mne.time_frequency.tfr_multitaper mne.time_frequency.tfr_array_multitaper mne.time_frequency.tfr_stockwell mne.time_frequency.tfr_array_stockwell File: c: users babib anaconda3 envs mne lib site-packages mne time_frequency tfr.py Type: function . freqs = list(range(3, 30)) tfr_target = tfr_morlet(epochs_for_tfr[&quot;target&quot;], freqs, 3, return_itc=False) tfr_standard = tfr_morlet(epochs_for_tfr[&quot;standard&quot;], freqs, 3, return_itc=False) . tfr_target.data.shape . (63, 27, 201) . Time-frequency data (single trial or averaged) is stored in TFR objects. These objects behave in many ways like Evoked objects ... . tfr_contrast = mne.combine_evoked((tfr_standard, tfr_target), (-.5, .5)) tfr_contrast.apply_baseline((None, 0)) . Applying baseline correction (mode: mean) . &lt;AverageTFR | time : [-0.500000, 1.500000], freq : [3.000000, 29.000000], nave : 212, channels : 63, ~2.7 MB&gt; . Plotting time-frequencyy activity (event-related spectral perturbations): observe the alpha-band ERD and the time-frequency correlates of the P3 effect. . tfr_contrast.plot_joint(); . No baseline correction applied No baseline correction applied . tfr_contrast.plot(picks=[13]); . No baseline correction applied .",
            "url": "https://berdakh.github.io/blog/eeg/jupyter/2020/09/14/MNE-Tutorial-part-2.html",
            "relUrl": "/eeg/jupyter/2020/09/14/MNE-Tutorial-part-2.html",
            "date": " • Sep 14, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "MNE tutorial part 1",
            "content": "from IPython.display import YouTubeVideo YouTubeVideo(&#39;IYuAPisoUeI&#39;, width=800, height=400) . %matplotlib inline import mne import matplotlib.pyplot as plt . fname = &quot;oddball_example_small-fif.gz&quot; . Read in raw data; raw objects . raw = mne.io.read_raw_fif(fname) . Opening raw data file oddball_example_small-fif.gz... . &lt;ipython-input-4-78767f98f250&gt;:1: RuntimeWarning: This filename (oddball_example_small-fif.gz) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz or _meg.fif raw = mne.io.read_raw_fif(fname) . Isotrak not found Range : 2903 ... 112000 = 29.030 ... 1120.000 secs Ready. . Visualize sample data . raw.plot(duration=60.0, start=0.0, n_channels=16,); . The information about the object can be found at raw.info . print(raw.info) . &lt;Info | 10 non-empty values bads: [] ch_names: FP1, FP2, F7, F3, Fz, F4, F8, FC5, FC1, FC2, FC6, T7, C3, Cz, ... chs: 63 EEG, 1 STIM custom_ref_applied: True file_id: 4 items (dict) highpass: 0.1 Hz lowpass: 30.0 Hz meas_date: 2017-08-10 20:05:16 UTC meas_id: 4 items (dict) nchan: 64 projs: [] sfreq: 100.0 Hz &gt; . MNE is object oriented. Objects have corresponding methods. Check which by typing raw. and pressing TAB: . raw.filter . &lt;bound method BaseRaw.filter of &lt;Raw | oddball_example_small-fif.gz, 64 x 109098 (1091.0 s), ~120 kB, data not loaded&gt;&gt; . raw.resample raw.filter raw.drop_channels ... . Can we do further preprocessing?.. . raw.filter(1, 20) . RuntimeError Traceback (most recent call last) &lt;ipython-input-8-780629dd327e&gt; in &lt;module&gt; -&gt; 1 raw.filter(1, 20) ~ anaconda3 envs mne lib site-packages mne io base.py in filter(self, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, phase, fir_window, fir_design, skip_by_annotation, pad, verbose) 926 skip_by_annotation=(&#39;edge&#39;, &#39;bad_acq_skip&#39;), 927 pad=&#39;reflect_limited&#39;, verbose=None): # noqa: D102 --&gt; 928 return super().filter( 929 l_freq, h_freq, picks, filter_length, l_trans_bandwidth, 930 h_trans_bandwidth, n_jobs, method, iir_params, phase, &lt;decorator-gen-111&gt; in filter(self, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, phase, fir_window, fir_design, skip_by_annotation, pad, verbose) ~ anaconda3 envs mne lib site-packages mne filter.py in filter(self, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, phase, fir_window, fir_design, skip_by_annotation, pad, verbose) 1920 &#34;&#34;&#34; 1921 from .io.base import BaseRaw -&gt; 1922 _check_preload(self, &#39;inst.filter&#39;) 1923 if pad is None and method != &#39;iir&#39;: 1924 pad = &#39;edge&#39; ~ anaconda3 envs mne lib site-packages mne utils check.py in _check_preload(inst, msg) 187 name = &#34;epochs&#34; if isinstance(inst, BaseEpochs) else &#39;raw&#39; 188 if not inst.preload: --&gt; 189 raise RuntimeError( 190 &#34;By default, MNE does not load data into main memory to &#34; 191 &#34;conserve resources. &#34; + msg + &#39; requires %s data to be &#39; RuntimeError: By default, MNE does not load data into main memory to conserve resources. inst.filter requires raw data to be loaded. Use preload=True (or string) in the constructor or raw.load_data(). . By default, MNE does not store raw and epochs objects in memory. . raw = mne.io.read_raw_fif(fname, preload=True) . Opening raw data file oddball_example_small-fif.gz... . &lt;ipython-input-9-7341ee706cdd&gt;:1: RuntimeWarning: This filename (oddball_example_small-fif.gz) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz or _meg.fif raw = mne.io.read_raw_fif(fname, preload=True) . Isotrak not found Range : 2903 ... 112000 = 29.030 ... 1120.000 secs Ready. Reading 0 ... 109097 = 0.000 ... 1090.970 secs... . raw.filter(1, 20) . Filtering raw data in 1 contiguous segment Setting up band-pass filter from 1 - 20 Hz FIR filter parameters Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 1.00 - Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz) - Upper passband edge: 20.00 Hz - Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz) - Filter length: 331 samples (3.310 sec) . &lt;Raw | oddball_example_small-fif.gz, 64 x 109098 (1091.0 s), ~53.4 MB, data loaded&gt; . Inspecting raw data ... . raw.plot(duration=60.0, start=0.0, n_channels=16,); . There are many eog artefacts. We will use ICA to correct these. For this, we create an ICA object and use its .fit method on a filtered copy of the raw data: . ICA decomposition . ica = mne.preprocessing.ICA(n_components=20, random_state=0) . ica.fit(raw.copy().filter(8, 35)) . Filtering raw data in 1 contiguous segment Setting up band-pass filter from 8 - 35 Hz FIR filter parameters Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 8.00 - Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz) - Upper passband edge: 35.00 Hz - Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz) - Filter length: 165 samples (1.650 sec) Fitting ICA to data using 63 channels (please be patient, this may take a while) Inferring max_pca_components from picks Selecting by number: 20 components Fitting ICA took 6.9s. . &lt;ICA | raw data decomposition, fit (fastica): 109098 samples, 20 components, channels used: &#34;eeg&#34;&gt; . ica.plot_components(outlines=&quot;skirt&quot;); . We store &quot;bad&quot; components in the ica object. . ica.exclude = [1, 10, 14, 17, 18, 19] . We could also use one of the automatic algorithms ... . bad_idx, scores = ica.find_bads_eog(raw, &#39;SO2&#39;, threshold=2) print(bad_idx) . Using channel SO2 as EOG channel ... filtering ICA sources Setting up band-pass filter from 1 - 10 Hz FIR filter parameters Designing a two-pass forward and reverse, zero-phase, non-causal bandpass filter: - Windowed frequency-domain design (firwin2) method - Hann window - Lower passband edge: 1.00 - Lower transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 0.75 Hz) - Upper passband edge: 10.00 Hz - Upper transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 10.25 Hz) - Filter length: 1024 samples (10.240 sec) ... filtering target Setting up band-pass filter from 1 - 10 Hz FIR filter parameters Designing a two-pass forward and reverse, zero-phase, non-causal bandpass filter: - Windowed frequency-domain design (firwin2) method - Hann window - Lower passband edge: 1.00 - Lower transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 0.75 Hz) - Upper passband edge: 10.00 Hz - Upper transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 10.25 Hz) - Filter length: 1024 samples (10.240 sec) [14, 10] . Let&#39;s compare raw and corrected data ... . Before ICA plot . raw.plot(duration=60.0, start=0.0, n_channels=16,); . After ICA plot . ica.apply(raw.copy(), exclude=ica.exclude).plot(duration=60.0, start=0.0, n_channels=16); . Transforming to ICA space (20 components) Zeroing out 6 ICA components . Epochs . For epoching the data, we need event markers. Usually, these are stored in the raw object; in MNE, in a stimulus channel. . mne.find_events? . Signature: mne.find_events( raw, stim_channel=None, output=&#39;onset&#39;, consecutive=&#39;increasing&#39;, min_duration=0, shortest_event=2, mask=None, uint_cast=False, mask_type=&#39;and&#39;, initial_event=False, verbose=None, ) Docstring: Find events from raw file. See :ref:`tut-events-vs-annotations` and :ref:`tut-event-arrays` for more information about events. Parameters - raw : Raw object The raw data. stim_channel : None | str | list of str Name of the stim channel or all the stim channels affected by triggers. If None, the config variables &#39;MNE_STIM_CHANNEL&#39;, &#39;MNE_STIM_CHANNEL_1&#39;, &#39;MNE_STIM_CHANNEL_2&#39;, etc. are read. If these are not found, it will fall back to &#39;STI 014&#39; if present, then fall back to the first channel of type &#39;stim&#39;, if present. If multiple channels are provided then the returned events are the union of all the events extracted from individual stim channels. output : &#39;onset&#39; | &#39;offset&#39; | &#39;step&#39; Whether to report when events start, when events end, or both. consecutive : bool | &#39;increasing&#39; If True, consider instances where the value of the events channel changes without first returning to zero as multiple events. If False, report only instances where the value of the events channel changes from/to zero. If &#39;increasing&#39;, report adjacent events only when the second event code is greater than the first. min_duration : float The minimum duration of a change in the events channel required to consider it as an event (in seconds). shortest_event : int Minimum number of samples an event must last (default is 2). If the duration is less than this an exception will be raised. mask : int | None The value of the digital mask to apply to the stim channel values. If None (default), no masking is performed. uint_cast : bool If True (default False), do a cast to ``uint16`` on the channel data. This can be used to fix a bug with STI101 and STI014 in Neuromag acquisition setups that use channel STI016 (channel 16 turns data into e.g. -32768), similar to ``mne_fix_stim14 --32`` in MNE-C. .. versionadded:: 0.12 mask_type : &#39;and&#39; | &#39;not_and&#39; The type of operation between the mask and the trigger. Choose &#39;and&#39; (default) for MNE-C masking behavior. .. versionadded:: 0.13 initial_event : bool If True (default False), an event is created if the stim channel has a value different from 0 as its first sample. This is useful if an event at t=0s is present. .. versionadded:: 0.16 verbose : bool, str, int, or None If not None, override default verbose level (see :func:`mne.verbose` and :ref:`Logging documentation &lt;tut_logging&gt;` for more). Returns - events : array, shape = (n_events, 3) All events that were found. The first column contains the event time in samples and the third column contains the event id. For output = &#39;onset&#39; or &#39;step&#39;, the second column contains the value of the stim channel immediately before the event/step. For output = &#39;offset&#39;, the second column contains the value of the stim channel after the event offset. See Also -- find_stim_steps : Find all the steps in the stim channel. read_events : Read events from disk. write_events : Write events to disk. Notes -- .. warning:: If you are working with downsampled data, events computed before decimation are no longer valid. Please recompute your events after decimation, but note this reduces the precision of event timing. Examples -- Consider data with a stim channel that looks like:: [0, 32, 32, 33, 32, 0] By default, find_events returns all samples at which the value of the stim channel increases:: &gt;&gt;&gt; print(find_events(raw)) # doctest: +SKIP [[ 1 0 32] [ 3 32 33]] If consecutive is False, find_events only returns the samples at which the stim channel changes from zero to a non-zero value:: &gt;&gt;&gt; print(find_events(raw, consecutive=False)) # doctest: +SKIP [[ 1 0 32]] If consecutive is True, find_events returns samples at which the event changes, regardless of whether it first returns to zero:: &gt;&gt;&gt; print(find_events(raw, consecutive=True)) # doctest: +SKIP [[ 1 0 32] [ 3 32 33] [ 4 33 32]] If output is &#39;offset&#39;, find_events returns the last sample of each event instead of the first one:: &gt;&gt;&gt; print(find_events(raw, consecutive=True, # doctest: +SKIP ... output=&#39;offset&#39;)) [[ 2 33 32] [ 3 32 33] [ 4 0 32]] If output is &#39;step&#39;, find_events returns the samples at which an event starts or ends:: &gt;&gt;&gt; print(find_events(raw, consecutive=True, # doctest: +SKIP ... output=&#39;step&#39;)) [[ 1 0 32] [ 3 32 33] [ 4 33 32] [ 5 32 0]] To ignore spurious events, it is also possible to specify a minimum event duration. Assuming our events channel has a sample rate of 1000 Hz:: &gt;&gt;&gt; print(find_events(raw, consecutive=True, # doctest: +SKIP ... min_duration=0.002)) [[ 1 0 32]] For the digital mask, if mask_type is set to &#39;and&#39; it will take the binary representation of the digital mask, e.g. 5 -&gt; &#39;00000101&#39;, and will allow the values to pass where mask is one, e.g.:: 7 &#39;0000111&#39; &lt;- trigger value 37 &#39;0100101&#39; &lt;- mask - 5 &#39;0000101&#39; For the digital mask, if mask_type is set to &#39;not_and&#39; it will take the binary representation of the digital mask, e.g. 5 -&gt; &#39;00000101&#39;, and will block the values where mask is one, e.g.:: 7 &#39;0000111&#39; &lt;- trigger value 37 &#39;0100101&#39; &lt;- mask - 2 &#39;0000010&#39; File: c: users babib anaconda3 envs mne lib site-packages mne event.py Type: function . events = mne.find_events(raw) . 903 events found Event IDs: [100 200] . events is simply an array (time in samples, zero, trigger); . events . array([[ 3241, 0, 200], [ 3437, 0, 200], [ 3643, 0, 200], ..., [111496, 0, 200], [111613, 0, 200], [111719, 0, 200]], dtype=int64) . ... which we can visualize: . plt.rcParams[&#39;figure.figsize&#39;] = [10, 5] . mne.viz.plot_events(events[:100]); . For creating an mne.Epochs object, we require, in addition to the raw object and the events array, a dictionary of the intended condition names and the corresponding trigger numbers. . event_ids = {&quot;standard/stimulus&quot;: 200, &quot;target/stimulus&quot;: 100} epochs = mne.Epochs(raw, events, event_id=event_ids) . 903 matching events found Applying baseline correction (mode: mean) Not setting metadata 0 projection items activated . epochs.plot(); . Loading data for 903 events and 71 original time points ... 0 bad epochs dropped Loading data for 903 events and 71 original time points ... Loading data for 20 events and 71 original time points ... . (changing to the inline backend now to speed things up.) . epochs = ica.apply(epochs, exclude=ica.exclude) . RuntimeError Traceback (most recent call last) &lt;ipython-input-26-6221a76f7f3f&gt; in &lt;module&gt; -&gt; 1 epochs = ica.apply(epochs, exclude=ica.exclude) ~ anaconda3 envs mne lib site-packages mne preprocessing ica.py in apply(self, inst, include, exclude, n_pca_components, start, stop) 1405 _check_compensation_grade(self.info, inst.info, &#39;ICA&#39;, kind, 1406 ch_names=self.ch_names) -&gt; 1407 return meth(**kwargs) 1408 1409 def _check_exclude(self, exclude): ~ anaconda3 envs mne lib site-packages mne preprocessing ica.py in _apply_epochs(self, epochs, include, exclude, n_pca_components) 1436 def _apply_epochs(self, epochs, include, exclude, n_pca_components): 1437 &#34;&#34;&#34;Aux method.&#34;&#34;&#34; -&gt; 1438 _check_preload(epochs, &#34;ica.apply&#34;) 1439 1440 picks = pick_types(epochs.info, meg=False, ref_meg=False, ~ anaconda3 envs mne lib site-packages mne utils check.py in _check_preload(inst, msg) 187 name = &#34;epochs&#34; if isinstance(inst, BaseEpochs) else &#39;raw&#39; 188 if not inst.preload: --&gt; 189 raise RuntimeError( 190 &#34;By default, MNE does not load data into main memory to &#34; 191 &#34;conserve resources. &#34; + msg + &#39; requires %s data to be &#39; RuntimeError: By default, MNE does not load data into main memory to conserve resources. ica.apply requires epochs data to be loaded. Use preload=True (or string) in the constructor or epochs.load_data(). . Of course ... . epochs = mne.Epochs(raw, events, event_id=event_ids, preload=True) epochs = ica.apply(epochs, exclude=ica.exclude) . 903 matching events found Applying baseline correction (mode: mean) Not setting metadata 0 projection items activated Loading data for 903 events and 71 original time points ... 0 bad epochs dropped Transforming to ICA space (20 components) Zeroing out 6 ICA components . The mne.Epochs constructor has a number of options, such as time window lengths and rejection thresholds. Investigate them on your own. . Epochs objects also have various methods, different from raw objects - e.g., for baselining. . epochs.apply_baseline((None, 0)) . Applying baseline correction (mode: mean) . &lt;Epochs | 903 events (all good), -0.2 - 0.5 sec, baseline [None, 0], ~31.4 MB, data loaded, &#39;standard/stimulus&#39;: 797 &#39;target/stimulus&#39;: 106&gt; . ... and many more ... . epochs. . File &#34;&lt;ipython-input-29-0e32a7ceced3&gt;&#34;, line 1 epochs. ^ SyntaxError: invalid syntax . To subselect only a sample of epochs, a dict-like access mode is available. . epochs . &lt;Epochs | 903 events (all good), -0.2 - 0.5 sec, baseline [None, 0], ~31.4 MB, data loaded, &#39;standard/stimulus&#39;: 797 &#39;target/stimulus&#39;: 106&gt; . epochs[&quot;target&quot;] . &lt;Epochs | 106 events (all good), -0.2 - 0.5 sec, baseline [None, 0], ~3.8 MB, data loaded, &#39;target/stimulus&#39;: 106&gt; . Observe how tags selected by forward slashes - &quot;/&quot; - work. . epochs[&quot;stimulus&quot;] . &lt;Epochs | 903 events (all good), -0.2 - 0.5 sec, baseline [None, 0], ~31.4 MB, data loaded, &#39;standard/stimulus&#39;: 797 &#39;target/stimulus&#39;: 106&gt; . How does the epoched activity look like? . epochs.info . &lt;Info | 10 non-empty values bads: [] ch_names: FP1, FP2, F7, F3, Fz, F4, F8, FC5, FC1, FC2, FC6, T7, C3, Cz, ... chs: 63 EEG, 1 STIM custom_ref_applied: True file_id: 4 items (dict) highpass: 1.0 Hz lowpass: 20.0 Hz meas_date: 2017-08-10 20:05:16 UTC meas_id: 4 items (dict) nchan: 64 projs: [] sfreq: 100.0 Hz &gt; . epochs[&quot;target&quot;].plot_image(picks=[13]); . 106 matching events found No baseline correction applied Not setting metadata 0 projection items activated 0 bad epochs dropped . To ensure we have as many Oddball as Standard trials, we can run ... . epochs.equalize_event_counts(event_ids) epochs . Dropped 691 epochs: 0, 1, 2, 3, 4, 5, 6, 9, 12, 13, 14, 15, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 72, 73, 74, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 107, 108, 109, 110, 113, 114, 115, 116, 117, 118, 121, 122, 123, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 146, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 187, 188, 193, 194, 197, 198, 199, 200, 201, 202, 203, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 248, 249, 252, 253, 254, 257, 260, 261, 262, 263, 266, 267, 268, 269, 270, 271, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 290, 291, 292, 295, 296, 297, 298, 299, 300, 301, 302, 303, 306, 307, 308, 309, 310, 311, 312, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 343, 344, 345, 346, 347, 348, 349, 350, 353, 354, 355, 358, 359, 360, 361, 362, 363, 364, 365, 368, 369, 370, 371, 372, 375, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 432, 433, 434, 435, 438, 439, 442, 449, 450, 451, 452, 453, 458, 459, 464, 465, 466, 467, 472, 473, 474, 475, 476, 477, 482, 483, 484, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 546, 547, 548, 551, 552, 553, 554, 555, 558, 559, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 610, 611, 612, 615, 616, 619, 620, 621, 624, 625, 626, 627, 628, 629, 630, 631, 632, 635, 636, 637, 638, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 674, 675, 676, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 780, 781, 782, 785, 786, 787, 788, 791, 792, 793, 794, 795, 796, 799, 802, 805, 806, 809, 810, 811, 812, 813, 814, 817, 818, 821, 822, 823, 826, 827, 828, 829, 830, 831, 832, 833, 834, 837, 838, 839, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 872, 875, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902 . &lt;Epochs | 212 events (all good), -0.2 - 0.5 sec, baseline [None, 0], ~7.5 MB, data loaded, &#39;standard/stimulus&#39;: 106 &#39;target/stimulus&#39;: 106&gt; . We can write the Epochs object to disk so we don&#39;t have to repeat the preprocessing later ... . Save data . epochs.save(&quot;oddball2-epo.fif&quot;) # remember, the data has been cleaned of bad ICs . epochs_for_tfr = mne.Epochs(raw, events, event_id=event_ids, tmin=-.5, tmax=1.5, preload=True) # need longer data segment . 903 matching events found Applying baseline correction (mode: mean) Not setting metadata 0 projection items activated Loading data for 903 events and 201 original time points ... 0 bad epochs dropped . epochs_for_tfr.plot(); . epochs_for_tfr = ica.apply(epochs_for_tfr, exclude=ica.exclude) epochs_for_tfr.equalize_event_counts(event_ids); # to speed up things #epochs_for_tfr.save(&quot;oddball-long-epo.fif&quot;) . Transforming to ICA space (20 components) Zeroing out 6 ICA components Dropped 0 epochs: . Get Numpy Array . X = epochs.get_data() . X.shape . (212, 64, 71) . type(X) . numpy.ndarray . epochs[&#39;target&#39;].get_data().shape . (106, 64, 71) . Xtarget = epochs[&#39;target&#39;].get_data() Xnontarget = epochs[&#39;standard&#39;].get_data() . Xtarget.shape . (106, 64, 71) . Xnontarget.shape . (106, 64, 71) .",
            "url": "https://berdakh.github.io/blog/eeg/jupyter/2020/09/10/MNE-Tutorial.html",
            "relUrl": "/eeg/jupyter/2020/09/10/MNE-Tutorial.html",
            "date": " • Sep 10, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Motor Imagery EEG Visualization using MNE",
            "content": "import matplotlib.pyplot as plt import numpy as np . %matplotlib inline %load_ext autoreload %autoreload 2 #%matplotlib qt . plt.rcParams[&#39;font.size&#39;] = 12 #plt.style.use(&#39;ggplot&#39;) plt.rcParams[&quot;axes.grid&quot;] = True c = plt.rcParams[&#39;axes.prop_cycle&#39;].by_key()[&#39;color&#39;] plt.rcParams[&#39;figure.figsize&#39;] = 8, 4 . from nu_smrutils import loaddat . dname = dict(BNCI2014004 = &#39;aBNCI2014004R.pickle&#39;, BNCI2014001 = &#39;aBNCI2014001R.pickle&#39;, Weibo2014 = &#39;aWeibo2014R.pickle&#39;, Physionet = &#39;aPhysionetRR.pickle&#39;) . Load data . Load EEG data for visualization . # itemname is one of : [&#39;BNCI2014004&#39;, &#39;BNCI2014001&#39;, &#39;Weibo2014&#39;, &#39;Physionet&#39;] itemname = &#39;BNCI2014001&#39; . filename = dname[itemname] iname = itemname + &#39;__&#39; data = loaddat(filename) print(&#39;Number of subjects in data :&#39;, len(data)) . Number of subjects in data : 9 . # select data from on subject and use it for demostration subject = 0 s1 = data[subject] print(s1) . &lt;Epochs | 288 events (all good), 2 - 6 sec, baseline off, ~15.6 MB, data loaded, &#39;left_hand&#39;: 144 &#39;right_hand&#39;: 144&gt; . s1[&#39;right_hand&#39;].plot(); . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; s1[&#39;right_hand&#39;].plot_psd(fmin=0, fmax=45); . Using multitaper spectrum estimation with 7 DPSS windows . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; Apply common-average reference . # use the average of all channels as reference s1.set_eeg_reference(ref_channels=&#39;average&#39;) s1[&#39;right_hand&#39;].plot(); . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; s1[&#39;right_hand&#39;].plot_psd(fmin=0, fmax=45); . Using multitaper spectrum estimation with 7 DPSS windows . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; Data info . print(s1.info) . &lt;Info | 17 non-empty fields bads : list | 0 items ch_names : list | Fz, FC3, FC1, FCz, FC2, FC4, C5, C3, C1, ... chs : list | 22 items (EEG: 22) comps : list | 0 items custom_ref_applied : bool | True dev_head_t : Transform | 3 items dig : list | 25 items (3 Cardinal, 22 EEG) events : list | 0 items highpass : float | 4.0 Hz hpi_meas : list | 0 items hpi_results : list | 0 items lowpass : float | 60.0 Hz meas_date : NoneType | unspecified nchan : int | 22 proc_history : list | 0 items projs : list | 0 items sfreq : float | 80.0 Hz acq_pars : NoneType acq_stim : NoneType ctf_head_t : NoneType description : NoneType dev_ctf_t : NoneType experimenter : NoneType file_id : NoneType gantry_angle : NoneType hpi_subsystem : NoneType kit_system_id : NoneType line_freq : NoneType meas_id : NoneType proj_id : NoneType proj_name : NoneType subject_info : NoneType xplotter_layout : NoneType &gt; . s1.plot_sensors(title = &#39;EEG sensor locations and labels&#39;, show_names = True); . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; Band-pass filter . Apply band-pass filter to extract $ mu$ and $ beta$ band EEG features between (8 - 30) Hz . s1.filter(l_freq = 8, h_freq = 30) . &lt;Epochs | 288 events (all good), 2 - 6 sec, baseline off, ~15.6 MB, data loaded, &#39;left_hand&#39;: 144 &#39;right_hand&#39;: 144&gt; . s1[&#39;right_hand&#39;].plot(); . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; s1[&#39;right_hand&#39;].plot_image(picks = [&#39;Cz&#39;], scalings = dict(eeg=1e6)) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; [&lt;Figure size 576x288 with 4 Axes&gt;] . s1[&#39;right_hand&#39;].plot_psd(fmin=0, fmax=45); . Using multitaper spectrum estimation with 7 DPSS windows . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; bands = [(4, 8, &#39;Theta&#39;), (8, 12, &#39;Mu Rhythm&#39;), (12, 30, &#39;Beta&#39;)] . s1[&#39;right_hand&#39;].plot_psd_topomap(bands = bands, normalize = True); . Using multitaper spectrum estimation with 7 DPSS windows . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; Get numpy array and visualize . print(&#39;EEG data is 3D numpy array (trials x channels x time samples) :&#39;, s1[&#39;right_hand&#39;].get_data().shape) . EEG data is 3D numpy array (trials x channels x time samples) : (144, 22, 321) . trial = 1 x = s1[&#39;right_hand&#39;].get_data()[trial,:,:] print(&#39;Channel x time samples :&#39;, x.shape) . Channel x time samples : (22, 321) . Plot single channel data from one trial . ch_names = s1.info[&#39;ch_names&#39;] ch_names . [&#39;Fz&#39;, &#39;FC3&#39;, &#39;FC1&#39;, &#39;FCz&#39;, &#39;FC2&#39;, &#39;FC4&#39;, &#39;C5&#39;, &#39;C3&#39;, &#39;C1&#39;, &#39;Cz&#39;, &#39;C2&#39;, &#39;C4&#39;, &#39;C6&#39;, &#39;CP3&#39;, &#39;CP1&#39;, &#39;CPz&#39;, &#39;CP2&#39;, &#39;CP4&#39;, &#39;P1&#39;, &#39;Pz&#39;, &#39;P2&#39;, &#39;POz&#39;] . # which channel to plot? channel = &#39;C4&#39; chIndex = [i for i, j in enumerate(ch_names) if j == channel] . plt.plot(x[chIndex[0], :]) plt.title(channel) plt.ylabel(&#39;Amplitude&#39;) plt.xlabel(&#39;Time samples&#39;) . Text(0.5, 0, &#39;Time samples&#39;) .",
            "url": "https://berdakh.github.io/blog/eeg/jupyter/2020/09/01/EEG-Visualization.html",
            "relUrl": "/eeg/jupyter/2020/09/01/EEG-Visualization.html",
            "date": " • Sep 1, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Welcome Post!",
            "content": ". Nazarbayev University Brain-Machine Interfaces research focuses on the development and cross-validation of new neurotechnologies in Kazakhstan to improve the quality of life for disabled people, at the interface between engineering, robotics, and neuroscience. . Our research focus on developing neural interfaces to restore human motor functions after stroke, and developing brain-actuated assistive robotic systems for disabled persons as well as devising robust machine learning algorithms for Brain-Computer/Machine Interfaces. . . Research Projects . . Brain-Machine Interfaces for Neural Rehabilitation after Stroke . | The brain-machine interface (BMI) technology aims to restore motor function disability in patients after stroke. Our research work will contribute to the development and cross-validation of Kazakhstan’s BMI systems to improve disabled and motor-impaired people’s quality of life. It will focus on areas at the interface between engineering, robotics, neuroscience, and medicine. A physical human-robot interface will be designed and augmented with a non-invasive BMI to provide neural rehabilitation therapy for patients after stroke across a broad spectrum of impairment severity in the rehabilitation tasks. The key contributions of our work include: 1) devising advanced electroencephalogram (EEG) interface methods (e.g., signal processing and machine learning algorithms) to stroke patients and developing a BMI for the control of the therapeutic robot that will improve upper and lower limb motor function, and 2) to conduct clinical trials in collaboration with the local rehabilitation centers. Annually, over 49 thousand people suffer a stroke in Kazakhstan, 80% of them became wholly or partly disabled after the strokes (http://en.tengrinews.kz/health/-50-000-Kazakhstan-citizens-suffer-strokes-annually-9657/), and this research project will have a substantial impact in the engineering of novel tools for efficient stroke rehabilitation of patients locally. . . Design and Optimization of a P300 Visual Brain-Computer Interface Speller in the Kazakh Language. . | Approximately half a million people living with Amyotrophic Lateral Sclerosis (ALS), a neurological disease that affects voluntary movements, rapidly lose the ability to move their arms, legs, and face muscles. Gradually, ALS patients become unable to communicate. However, an ALS patient’s brain is fully functional; this is an opportunity that provides a gateway to developing assistive devices for communication. The only means of communication for those patients are using a Brain-Computer Interface (BCI). The BCI speller is a system that enables persons unable to communicate naturally due to neuromuscular diseases to share with the external world. It acquires brain signals in response to visual stimuli the person is shown to on the screen and then analyzes in real-time to predict the desired symbol. To date, most BCI design paradigms have been focused on the development of a speller to communicate English or Latin based languages. Due to a lack of BCI spellers for patients speaking the Kazakh language, this study will design and optimize a novel BCI speller in collaboration with the local medical centers to enable thousands of ALS patients to communicate the Kazakh language. The BCI speller could also be potentially useful for people with communication problems: persons afflicted with brain or spinal cord injuries, multiple sclerosis, muscular dystrophies, and cerebral palsy. . . Feature Representation Learning of High-Frequency Oscillations relevant to Ictogenesis . | Epilepsy affects approximately 1% of the population, and about 30~40% of them fail to control seizures with medications. For these patients with medically refractory epilepsy, epilepsy surgery is the best treatment option currently available. The success of epilepsy surgery largely depends on the precise localization of the epileptogenic region, brain areas capable of generating spontaneous seizures now or in the future and should be surgically removed or disconnected. The current clinical practice encompasses identifying the seizure-onset zone (SOZ) and extended epileptic area (or irritative zone) by multiple days of intracranial EEG recordings and the surgical resection of these regions. However, these invasive procedures do not always warrant a favorable surgical outcome: the seizure freedom rate after surgery declines with time for its worse. Among many candidates of an electrophysiological biomarker of the epileptic brain, high-frequency oscillations (HFO) are becoming the most promising ones. This study investigates how different types of HFOs are related to Ictogenesis by developing a mathematical framework such as feature representation learning algorithms. To manifest the existence of novel predictive/distinct features that are hidden but important biomarkers useful for accurate delineation of SOZ. The proposed machine learning-based extraction of HFO signatures will help physicians: 1) to indicate accurate localization of the epileptogenic zone in pre-surgical evaluations, and 2) to better understand which epileptic HFO discharges are highly relevant to the ictal onset zone and lead to better postsurgical outcomes. . .",
            "url": "https://berdakh.github.io/blog/markdown/2020/01/14/Welcome.html",
            "relUrl": "/markdown/2020/01/14/Welcome.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  

  
      ,"page2": {
          "title": "Publications",
          "content": "Patents | Journal Publications | Conference Publications | . Patents . J. An, S.H. Jin, S.H. Lee, J.I. Moon B. Abibullaev, J.H. Ahn and G.H. Jang. REHABILITATION TRAINING SYSTEM AND METHOD. : 9,081,890,Washington, DC: United States. Patent and Trademark Office, 2015 (https://www.google.com/patents/US9081890). . | J. An, S.H. Jin, S.H. Lee, J.I. Moon B. Abibullaev, J.H. Ahn and G.H. Jang. Self-directed rehabilitation training method combining brain signals and functional electro-stimulation. : 17077057, Application number: 14049302, 09-OCT-2013, United States, (http://www.google.com/patents/US20140200632). . | . Journal Publications . B. Abibullaev, I.Dolzhikova and A. Zollanvari. A Brute-force CNN Model Selection for Accurate Classification of Sensorimotor Rhythms in BCIs IEEE Access, DOI: 10.1109/ACCESS.2020.2997681, 2020. . | A. Zollanvari, M. Abdirash, A. Dadlani and B. Abibullaev. Asymptotically Bias-Corrected Regularized Linear Discriminant Analysis for Cost-Sensitive Binary Classification IEEE Signal Processing Letters, 2019. . | B. Abibullaev and A. Zollanvari. Learning Discriminative Spatiospectral Features of ERPs for Accurate Brain-Computer Interfaces IEEE Journal of Biomedical and Health Informatics, vol. 98, pp.1-12, 2019. . | B. Abibullaev, A. Zollanvari, B. Saduanov, and T. Alizadeh. Design and Optimization of a BCI-Driven Telepresence Robot Through Programming by Demonstration. IEEE Access, 2019, vol. 7. . | N.A. Bhagat, A. Venkatakrishnan, B. Abibullaev, E.J. Artz, N. Yozbatiran, A. Blank, J. French, C. Karmonik, R.G.Grossman, M.K O’Malley, G. Francisco, J.L. Contreras-Vidal. Design and optimization of an EEG-based brain machine interface (BMI) to an upper-limb exoskeleton for stroke survivors. , vol. 10, March, 2016. . | B Abibullaev, J An, SH Lee, JI Moon. Design and Evaluation of Action Observation and Motor Imagery based BCIs using NIRS. Measurement, vol. 98, pp. 250-261, 2017, Elsevier. . | J.G. Cruz-Garza, Z.R. Hernandez, T. Tse, E. Caducoy, B. Abibullaev, J.L. Contreras-Vidal. A novel experimental and analytical approach to the multimodal neural decoding of intent during social interaction in freely-behaving human infants; JoVE (Journal of Visualized Experiments), doi:10.3791/53406, October, 2015. . | C.H. Park, J.H Seo, D. Kim, B. Abibullaev, H. Kwon, Y.H. Lee, M.Y. Kim, K. Kim, J.S. Kim, E.Y. Joo, S.B. Hong, (2015, Feb). Source Imaging in Partial Epilepsy in Comparison with Presurgical Evaluation and Magnetoencephalography. Journal of Clinical Neurology, 2015 Feb 17, 11:e12. . | B. Abibullaev, J An, S.H. Jin, and J.I. Moon. Classification of brain hemodynamic signals arising from visual action observation tasks for brain-computer interfaces: An fNIRS study, Measurement, 2014. Elsevier. . | B. Abibullaev, J An, S.H. Lee, S.H. Jin, and J.I. Moon. Minimizing inter-subject variability in FNIRS based brain computer interfaces via multiple-kernel support vector learning. Medical Engineering Physics, 2013. Elsevier. . | B. Abibullaev and J. An. Classification of frontal cortex hemodynamic response during cognitive tasks using wavelet transforms and machine learning algorithms. Medical Engineering Physics, 34(10):1394–410, 2012. Elsevier. . | B. Abibullaev and J. An. Decision support algorithm for diagnosis of ADHD disorder using electroencephalograms. Journal of Medical Systems, 36(4):2675–2688, 2011. Springer. . | B. Abibullaev, J. An, and J.I. Moon. Neural network classification of brain hemodynamic responses from four mental tasks. International Journal of Optomechatronics, 5(4):340–359, 2011. Taylor &amp; Francis. . | B. Abibullaev and H.D. Seo. A new QRS detection method using wavelets and artificial neural networks. Journal of Medical Systems, 35(4):683–691, 2011. Springer. . | B. Abibullaev, M.S. Kim, and H.D. Seo. Epileptic spike detection using continuous wavelet transforms and artificial neural networks. , 8(1):33–48, 2010. International journal of wavelets, multiresolution and information processing, Worldscientific. . | B. Abibullaev, M.S. Kim, and H.D. Seo. Seizure detection in temporal lobe epileptic EEGs using the best basis wavelet functions. Journal of Medical Systems, 34(4):755–765, 2010. Springer. . | . Conference Publications . A. Oleinikov, B. Abibullaev, M. Folgheraiter, “On the Classification of Electromyography Signals to Control a Four Degree-Of-Freedom Prosthetic Device,” in 2020 42nd Annual International Conference of the IEEE Engineering in Medicine &amp; Biology Society (EMBC) . | B. Saduanov, D. Tokmurzina, K. Kunanbayev and B. Abibullaev, “Design and Optimization of a Real-Time Asynchronous BCI Control Strategy for Robotic Manipulator Assistance”, in 2020 8th International Winter Conference on Brain-Computer Interface (BCI) . | A. Tuleuov and B. Abibullaev, “Deep Learning Models for Subject-Independent ERP-based Brain-Computer Interfaces,” in the 2019 9th International IEEE/EMBS Conference on Neural Engineering (NER), March 20-23, 2019, San Francisco, CA, USA. . | B. Abibullaev, Y. Orazayev, and A. Zollanvari, “Novel Spatiospectral Features of ERPs Enhances Brain-Computer Interfaces ,” in Brain-Computer Interface (BCI), 2019 7th International Conference on.1em plus 0.5em minus 0.4em IEEE, 2019, GangWon, South Korea. . | B. Saduanov, D. Tokmurzina, T. Alizadeh, and B. Abibullaev, “Brain-computer interface humanoid pre-trained for interaction with people,” in 2018 ACM/IEEE International Conference on Human-Robot Interaction.1em plus 0.5em minus 0.4emACM, March 5-8, 2018, pp. 229–230, Chicago, IL, USA. . | A. Oleinikov, B. Abibullaev, A. Shintemirov, and M. Folgheraiter, “Feature extraction and real-time recognition of hand motion intentions from emgs via artificial neural networks,” in Brain-Computer Interface (BCI), 2018 6th International Conference on.1em plus 0.5em minus 0.4em IEEE, 2018, pp. 1-5, GangWon, South Korea. . | G. Lee, S. H. Jin, S. T. Yang, J. An and B. Abibullaev, “Cross-correlation between HbO and HbR as an effective feature of motion artifact in fNIRS signal,” 2018 6th International Conference on Brain-Computer Interface (BCI), pp. 1-3, 2018, IEEE, GangWon, South Korea. . | B. Saduanov, T. Alizadeh, J. An, and B. Abibullaev, “Trained by demonstration humanoid robot controlled via a bci system for telepresence,” in Brain-Computer Interface (BCI), 2018 6th International Conference on.1em plus 0.5em minus 0.4emIEEE, 2018, pp. 1–4, January, GangWon, South Korea. . | B. Saduanov, T. Alizadeh, J. An, and B. Abibullaev, “Trained by demonstration humanoid robot controlled via a bci system for telepresence,” in Brain-Computer Interface (BCI), 2018 6th International Conference on.1em plus 0.5em minus 0.4emIEEE, 2018, pp. 1–4, January, GangWon, South Korea. . | G. Lee, S. H. Jin, S. H. Lee, B. Abibullaev, and J. An, “FNIRS motion artifact correction for overground walking using entropy based unbalanced optode decision and wavelet regression neural network,” in Multisensor Fusion and Integration for Intelligent Systems (MFI), 2017 IEEE International Conference on.1em plus 0.5em minus 0.4emIEEE, 2017, pp. 186–193, Daegu, South Korea. . | A. Zhumadilova, D. Tokmurzina, A. Kuderbekov and and B. Abibullaev. Design and Evaluation of a P300 Visual Brain-Computer Interface Speller in Cyrillic Characters. In the 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), IEEE, 2017, Aug 28 - Sept 1, Lisbon, Portugal. . | B. Abibullaev. Learning Suite of Kernel Feature Spaces Enhances SMR-Based EEG-BCI Classification. In the 5th International Winter Conference on Brain-Computer Interface, IEEE, 2017, January 9-11, GangWon, South Korea. . | D. Nurseitov, A. Serekov, A. Shintemirov and B. Abibullaev. Design and Evaluation of a P300-ERP based BCI System for Real-Time Control of a Mobile Robot. In the 5th International Winter Conference on Brain-Computer Interface, IEEE, 2017, January 9-11, Gangwon , South Korea. . | B. Abibullaev and J An. On Robust Classification of Hemodynamic Signals for BCIs via Multiple Kernel ν-SVMs. Intelligent Robots and Systems (IROS), 2016 IEEE/RSJ International Conference, 2016, Oct10-15, Daejeon, South Korea. . | J.G. Cruz-Garza, Z.R. Hernandez, M. Megjhani, B. Abibullaev, T. Tse, E. Caducoy, and JL Contreras-Vidal. Neural development of social cognition in the first two ears of life - Early findings. In Society for Neuroscience 2015 Oct 17-21; Chicago, USA. . | Z.R. Hernandez, A.J. Arenas-Castellanos, J.G. Cruz-Garza, M. Megjhani, B. Abibullaev, Sri. R.P. Maddi, T. Tse, C. Armstrong, W. Long, J.L. Contreras-Vidal Decoding Intent From Non-invasive EEG in Freely Behaving Infants In Ninth Biennial Meeting of the Cognitive Development Society 2015 Oct 9-10; Ohio, USA. . | A.J. Arenas-Castellanos, Z.R. Hernandez, J.G. Cruz-Garza, M. Megjhani, B. Abibullaev, Sri. R.P. Maddi, T. Tse, C. Armstrong, W. Long, J.L. Contreras-Vidal A developmental Analysis of Behaviors Related to the Mirror Neuron System in 6-24 Months Infants In Ninth Biennial Meeting of the Cognitive Development Society 2015 Oct 9-10; Ohio, USA. . | Z.R. Hernandez, J.G. Cruz-Garza, T. Tse, E. Caducoy, B. Abibullaev, J.L. Contreras-Vidal. Supervised Classification of Intended Behaviors Using Electroencephalography (EEG) from Freely-Behaving Infants: Early Findings. In 12th Annual GCC Conference on Theoretical and Computational Neuroscience, Rice University, Houston, TX, United States, February 6-7, 2015. . | N. A. Bhagat, A Venkatakrishnan, B. Abibullaev, E. J. Artz, A.A. Blank, J. A. French, N. Yozbatiran, and R. G. Grossman, M. K. OMalley, J. L. Contreras-Vidal, G. E. Francisco Control of a Therapeutic Exoskeleton to Facilitate Personalized Robotic Rehabilitation of the Upper Limb. , Westin Arlington, Nov. 19-20 2014, United States. . | C.H.Park, B. Abibullaev, E.Y. Joo, S.C. Hong, and S.B. Hong. The evaluation of accuracy and clinical usefulness of 3D EEG source localization analysis. In the 19th Korean Epilepsy Congress, Seoul, Republic of Korea, June 12-14 2014. . | S.H. Lee, J. An, G. Jang, S.H. Jin, B. Abibullaev, and J.I. Moon. Neural activity during observation, imagery, and execution of eating: An fNIRS pilot study. In the 19th Annual Meeting of the Organization for Human Brain Mapping, Seattle, WA, United States, June 16-20 2013. . | J. An, S.H. Jin, S.H. Lee, G. Jang, B. Abibullaev, J. Ahn, H. Lee, and J.I. Moon. Cortical activation pattern for grasping during observation, imagery, execution, FES, and observation-FES integrated BCI: An fNIRS pilot study. In the 35th Annual Int. Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), Osaka, Japan, July 3-7 2013. . | J. An, S.H. Lee, S.H. Jin, B. Abibullaev, G. Jang, J. Ahn, H. Lee, and J.I. Moon. The beginning of neurohaptics: Controlling cognitive interaction via brain haptic interface. In the 2013 IEEE International Winter Workshop on Brain-Computer Interface, Gangwon Province, Korea, Feb. 18-20 2013. . | B. Abibullaev, J. An, J.I. Moon, S.H. Lee, and S.H. Jin. A study on the BCI-Robot assisted stroke rehabilitation framework using brain hemodynamic signals. In the 9th Int Conference on Ubiquitous Robots and Ambient Intelligence, IEEE proceedings, Daejon, Korea, November 26-29,2012. . | B. Abibullaev, J. An, S.H.Lee, S.H. Jin, J.I Moon, H.J. Lee. Decoding of Brain Hemodynamic Responses for Brain-Computer Interfaces via Ensemble Support Vector Learning. In the Human-Computer Interaction Conference, Gangwon-Do, Korea, January 11-13,2012. . | B. Abibullaev, W.S. Kang, S.H. Lee, J. An, and H.D. Seo. Near-infrared spectroscopy in the analysis of functional brain activity during cognitive tasks. In 2010 IEEE Sensors Conference, Hawaii, United States, November 1-4, 2010. . | B. Abibullaev, W.S. Kang, S.H. Lee, and J. An. Recognition of brain hemodynamic mental response for brain-computer interface. In International Conference on Control Automation and Systems, IEEE proceedings, Gyeonggi-do, Korea, October 27-30 2010. . | S.H. Lee, B. Abibullaev, W.S. Kang, and J. An. Analysis of attention deficit hyperactivity disorder in EEG using wavelet transform and self organizing maps. In International Conference on Control Automation and Systems, IEEE proceedings, Gyeonggi-do, Korea, October 27-30 2010. . | W.S. Kang, B. Abibullaev, S.H. Lee, and J. An. Path planning algorithm using the values clustered by k-means. In the 15th Int. Symposium on Artificial Life and Robotics, Japan, February 4-6 2010. . | B. Abibullaev, H.D. Seo, W.S. Kang, and J. An. A wavelet-based method for detecting and localizing epileptic neural spikes in EEG signals. In the 2nd Int. Conf. on Interaction Sciences: Information Technology, Culture and Human. ACM, Seoul, Korea, Nov. 24- 26 2009. . | B. Abibullaev and H.D. Seo. Epileptic seizures detection using continuous time wavelet based neural networks. In the 6th International Conference on Information Technology: New Generations, IEEE Computer Society, Las Vegas,Nevada, United States, April 27-29 2009. . | W.S. Kang, B. Abibullaev, S.H. Lee, and J. An. A study on brain activation during playing a computer game using fNIRS. In the 32th conference of Korean Info. Proc. Soc., Seoul Korea, November 22-24,2009. . | B. Abibullaev, H.D. Seo, and M.S. Kim. Classification system of EEG during cognitive mental tasks. In Int. Conference on Engineering and ICT, Melaka, Malaysia, November 27-29, 2007. . | H.D. Seo and B. Abibullaev. Analysis of EEG signals by the continuous wavelet transforms. In the 5th Int. Joint Conference on Global Academic Networking, Vladivastok, Russia, June 7-9 2007. . | .",
          "url": "https://berdakh.github.io/blog/publication/",
          "relUrl": "/publication/",
          "date": ""
      }
      
  

  
  

  

  
  

  

  
      ,"page7": {
          "title": "Teaching",
          "content": "FALL Semester 2020 . Machine Learning with Applications (ROBT407) Course Description | Youtube lectures | . | Brain-Machine Interfaces (ROBT613) Course Description | Youtube lectures | . | . 1. Machine Learning with Applications (ROBT407) . 1.1. Course Description . ROBT 407 introduces the students to the state-of-the-art analytical tools and methods used for machine learning. Topics include (semi) supervised and unsupervised learning, neural networks, deep learning, support vector machines, the design of machine learning experiments, decision trees, linear discrimination and kernel-based learning methods. The course also contains integrated term projects. Python-based machine learning packages (e.g., scikitLearn, Pytorch, Numpy, Scipy, Pandas, Matplotlib) and online databases will be used extensively. . Course materials . | Textbook: LEARNING FROM DATA, Abu-Mostafa, Magdon-Ismail, Lin. Publication date and edition - 1st ed., March 27, 2012, ISBN Number - 1600490069 . | Textbook: Dive into Deep Learning : An interactive deep learning book with code, math, and discussions, Alex J. Smola et al. Carnegie Mellon University, and Amazon, https://d2l.ai/ . | . Prerequisites/Corequisites . ========================== . Prerequisites: MATH 273 Linear Algebra with Applications, MATH 321 Probability, (must be completed with a grade of “C-“ or better); . Course Objectives . ================= . Successful students: . Establish fundamental theoretical knowledge in statistical learning field . | Acquire core knowledge and practical skills on basic techniques of machine learning, including linear/nonlinear methods . | Be competent with theoretical analysis and formulation of statistical learning techniques for solving real-world data mining problems . | Be familiar with the wide class of methods for supervised/unsupervised data analysis, classification, regression, including linear/logistic regression, kernel methods, neural networks, and other methods. . | Course learning outcomes . ======================== . At the completion of this course, students will know the following areas: . Demonstrate an understanding of different types of learning algorithms used in engineering fields. . | Design and implement machine learning algorithms for feature extraction, classification, and clustering. . | Demonstrate hands-on experience with practical data mining using machine learning algorithms and implement those algorithms in different programming languages. . | Use advanced machine learning tools for data analysis. . | . Youtube lectures . . . 2. Brain-Machine Interfaces (ROBT613) . Course Description . Brain-Machine Interface (BMI) systems are an emerging interdisciplinary field at the intersection of engineering, neuroscience, and medicine. It has brought promising new perspectives to human-machine interaction using brain activity. It provides users the capability to control applications such as assistive robotic technologies directly. This course is an introduction to the fundamentals of BMI technology and discusses its applications including both invasive and non-invasive BMI systems for controlling user interfaces, prosthetic arms, wheelchairs, and robotic exoskeletons. The course will also introduce other clinical applications of BMI technology for patients with locked-in syndrome and its utility in restoring movement and mobility in severely paralyzed persons. Also, other nonclinical use of BMI technology will be studied with hands-on experiments/projects for applications such as security, alertness monitoring, entertainment, gaming, and education or human augmentation. . The course will be delivered in the form of mixed lectures with case studies and discussion of research papers led by student groups, and in-class demonstration of BMI systems using the systems available at NU. The lecture series will cover core topics related to neural signal processing and machine learning algorithms that convert EEG features into control commands (i.e. an upper-limb rehabilitative robot). Python /Matlab and related signal processing and machine learning libraries will be used extensively. . Course materials . | Textbook: • Wolpaw, Jonathan, and Elizabeth Winter Wolpaw. Brain-computer interfaces: principles and practice. OUP, USA, 2012. . | . Course Objectives . ================= . Successful students: . Establish fundamental knowledge and skills to analyze EEG, MEG, and hemodynamic brain signals . | Acquire core knowledge and practical skills related to EEG, MEG analysis and decoding, which are relevant for brain machine interface research. . | Work independently, plan and carry out necessary laboratory experiments on brain data acquisition . | Present the results through seminar discussions and reports . | Course learning outcomes . ======================== . At the completion of this course, students will know the following areas: . to plan and carry out Brain-Machine Interface experiments, | to obtain programming skills required to design interfaces with human and machines, | to analyze the data and interpret their findings and present them scientifically | Use advanced machine learning tools for brain data analysis. | . Youtube lectures . . .",
          "url": "https://berdakh.github.io/blog/teaching/",
          "relUrl": "/teaching/",
          "date": ""
      }
      
  

  
  

  
  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://berdakh.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}