{
  
    
        "post0": {
            "title": "MNE tutorial part 2",
            "content": "from IPython.display import YouTubeVideo YouTubeVideo(&#39;29hjjxdt1zE&#39;, width=800, height=400) . %matplotlib inline import mne import matplotlib.pyplot as plt . fname = &quot;oddball-epo.fif&quot; . epochs = mne.read_epochs(fname) . Reading oddball-epo.fif ... Isotrak not found Found the data of interest: t = -200.00 ... 500.00 ms 0 CTF compensation matrices available 212 matching events found Applying baseline correction (mode: mean) Not setting metadata 0 projection items activated . epochs . &lt;EpochsFIF | 212 events (all good), -0.2 - 0.5 sec, baseline [-0.2, 0], ~7.5 MB, data loaded, &#39;standard/stimulus&#39;: 106 &#39;target/stimulus&#39;: 106&gt; . epochs.get_data().shape . (212, 64, 71) . Evoked . Finally, if we average an epoched dataset over trials, we can use the mne.Evoked object. . target = epochs[&quot;target&quot;].average() target . &lt;Evoked | &#39;target/stimulus&#39; (average, N=106), [-0.2, 0.5] sec, 63 ch, ~153 kB&gt; . standard = epochs[&quot;standard&quot;].average() . epochs[].get_data().shape . (212, 64, 71) . epochs[&#39;target&#39;].get_data().shape . (106, 64, 71) . target.data.shape . (63, 71) . target.info . &lt;Info | 10 non-empty values bads: [] ch_names: FP1, FP2, F7, F3, Fz, F4, F8, FC5, FC1, FC2, FC6, T7, C3, Cz, ... chs: 63 EEG custom_ref_applied: True file_id: 4 items (dict) highpass: 1.0 Hz lowpass: 20.0 Hz meas_date: 2017-08-10 20:05:16 UTC meas_id: 4 items (dict) nchan: 63 projs: [] sfreq: 100.0 Hz &gt; . To quickly investigate evoked activity, the Evoked object has a number of plotting functions available. . target.info[&#39;ch_names&#39;] . [&#39;FP1&#39;, &#39;FP2&#39;, &#39;F7&#39;, &#39;F3&#39;, &#39;Fz&#39;, &#39;F4&#39;, &#39;F8&#39;, &#39;FC5&#39;, &#39;FC1&#39;, &#39;FC2&#39;, &#39;FC6&#39;, &#39;T7&#39;, &#39;C3&#39;, &#39;Cz&#39;, &#39;C4&#39;, &#39;T8&#39;, &#39;CP5&#39;, &#39;CP1&#39;, &#39;CP2&#39;, &#39;CP6&#39;, &#39;P7&#39;, &#39;P3&#39;, &#39;Pz&#39;, &#39;P4&#39;, &#39;P8&#39;, &#39;PO9&#39;, &#39;O1&#39;, &#39;Oz&#39;, &#39;O2&#39;, &#39;PO10&#39;, &#39;AF7&#39;, &#39;AF3&#39;, &#39;AF4&#39;, &#39;AF8&#39;, &#39;F5&#39;, &#39;F1&#39;, &#39;F2&#39;, &#39;F6&#39;, &#39;SO1&#39;, &#39;FT7&#39;, &#39;FC3&#39;, &#39;FC4&#39;, &#39;FT8&#39;, &#39;SO2&#39;, &#39;C5&#39;, &#39;C1&#39;, &#39;C2&#39;, &#39;C6&#39;, &#39;TP7&#39;, &#39;CP3&#39;, &#39;CPz&#39;, &#39;CP4&#39;, &#39;TP8&#39;, &#39;P5&#39;, &#39;P1&#39;, &#39;P2&#39;, &#39;P6&#39;, &#39;PO7&#39;, &#39;PO3&#39;, &#39;POz&#39;, &#39;PO4&#39;, &#39;PO8&#39;, &#39;FCz&#39;] . dir(target) . [&#39;__class__&#39;, &#39;__contains__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__ne__&#39;, &#39;__neg__&#39;, &#39;__new__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__slotnames__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;, &#39;_aspect_kind&#39;, &#39;_data&#39;, &#39;_get_channel_positions&#39;, &#39;_pick_drop_channels&#39;, &#39;_projector&#39;, &#39;_set_channel_positions&#39;, &#39;_size&#39;, &#39;_update_first_last&#39;, &#39;add_channels&#39;, &#39;add_proj&#39;, &#39;animate_topomap&#39;, &#39;anonymize&#39;, &#39;apply_baseline&#39;, &#39;apply_hilbert&#39;, &#39;apply_proj&#39;, &#39;as_type&#39;, &#39;ch_names&#39;, &#39;comment&#39;, &#39;compensation_grade&#39;, &#39;copy&#39;, &#39;crop&#39;, &#39;data&#39;, &#39;decimate&#39;, &#39;del_proj&#39;, &#39;detrend&#39;, &#39;drop_channels&#39;, &#39;filter&#39;, &#39;first&#39;, &#39;get_channel_types&#39;, &#39;get_peak&#39;, &#39;info&#39;, &#39;interpolate_bads&#39;, &#39;kind&#39;, &#39;last&#39;, &#39;nave&#39;, &#39;pick&#39;, &#39;pick_channels&#39;, &#39;pick_types&#39;, &#39;picks&#39;, &#39;plot&#39;, &#39;plot_field&#39;, &#39;plot_image&#39;, &#39;plot_joint&#39;, &#39;plot_projs_topomap&#39;, &#39;plot_sensors&#39;, &#39;plot_topo&#39;, &#39;plot_topomap&#39;, &#39;plot_white&#39;, &#39;preload&#39;, &#39;proj&#39;, &#39;rename_channels&#39;, &#39;reorder_channels&#39;, &#39;resample&#39;, &#39;save&#39;, &#39;savgol_filter&#39;, &#39;set_channel_types&#39;, &#39;set_eeg_reference&#39;, &#39;set_meas_date&#39;, &#39;set_montage&#39;, &#39;shift_time&#39;, &#39;time_as_index&#39;, &#39;times&#39;, &#39;to_data_frame&#39;, &#39;verbose&#39;] . &#39;plot&#39;, &#39;plot_field&#39;, &#39;plot_image&#39;, &#39;plot_joint&#39;, &#39;plot_projs_topomap&#39;, &#39;plot_sensors&#39;, &#39;plot_topo&#39;, &#39;plot_topomap&#39;, &#39;plot_white&#39;, Visualization . target.plot(); . target.plot_topomap? . Signature: target.plot_topomap( times=&#39;auto&#39;, ch_type=None, layout=None, vmin=None, vmax=None, cmap=None, sensors=True, colorbar=True, scalings=None, units=None, res=64, size=1, cbar_fmt=&#39;%3.1f&#39;, time_unit=&#39;s&#39;, time_format=None, proj=False, show=True, show_names=False, title=None, mask=None, mask_params=None, outlines=&#39;head&#39;, contours=6, image_interp=&#39;bilinear&#39;, average=None, head_pos=None, axes=None, extrapolate=&#39;box&#39;, sphere=None, border=0, nrows=1, ncols=&#39;auto&#39;, ) Docstring: Plot topographic maps of specific time points of evoked data. Parameters - times : float | array of float | &#34;auto&#34; | &#34;peaks&#34; | &#34;interactive&#34; The time point(s) to plot. If &#34;auto&#34;, the number of ``axes`` determines the amount of time point(s). If ``axes`` is also None, at most 10 topographies will be shown with a regular time spacing between the first and last time instant. If &#34;peaks&#34;, finds time points automatically by checking for local maxima in global field power. If &#34;interactive&#34;, the time can be set interactively at run-time by using a slider. ch_type : &#39;mag&#39; | &#39;grad&#39; | &#39;planar1&#39; | &#39;planar2&#39; | &#39;eeg&#39; | None The channel type to plot. For &#39;grad&#39;, the gradiometers are collected in pairs and the RMS for each pair is plotted. If None, then channels are chosen in the order given above. layout : None Deprecated and will be removed in 0.21. Use ``sphere`` to control head-sensor relationship instead. vmin : float | callable | None The value specifying the lower bound of the color range. If None, and vmax is None, -vmax is used. Else np.min(data). If callable, the output equals vmin(data). Defaults to None. vmax : float | callable | None The value specifying the upper bound of the color range. If None, the maximum absolute value is used. If callable, the output equals vmax(data). Defaults to None. cmap : matplotlib colormap | (colormap, bool) | &#39;interactive&#39; | None Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range (zoom). The mouse scroll can also be used to adjust the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None (default), &#39;Reds&#39; is used for all positive data, otherwise defaults to &#39;RdBu_r&#39;. If &#39;interactive&#39;, translates to (None, True). .. warning:: Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps. sensors : bool | str Add markers for sensor locations to the plot. Accepts matplotlib plot format string (e.g., &#39;r+&#39; for red plusses). If True (default), circles will be used. colorbar : bool | None Plot a colorbar in the rightmost column of the figure. None (default) is the same as True, but emits a warning if custom ``axes`` are provided to remind the user that the colorbar will occupy the last :class:`matplotlib.axes.Axes` instance. scalings : dict | float | None The scalings of the channel types to be applied for plotting. If None, defaults to ``dict(eeg=1e6, grad=1e13, mag=1e15)``. units : dict | str | None The unit of the channel type used for colorbar label. If scale is None the unit is automatically determined. res : int The resolution of the topomap image (n pixels along each side). size : float Side length per topomap in inches. cbar_fmt : str String format for colorbar values. time_unit : str The units for the time axis, can be &#34;ms&#34; or &#34;s&#34; (default). .. versionadded:: 0.16 time_format : str | None String format for topomap values. Defaults (None) to &#34;%01d ms&#34; if ``time_unit=&#39;ms&#39;``, &#34;%0.3f s&#34; if ``time_unit=&#39;s&#39;``, and &#34;%g&#34; otherwise. proj : bool | &#39;interactive&#39; If true SSP projections are applied before display. If &#39;interactive&#39;, a check box for reversible selection of SSP projection vectors will be show. show : bool Show figure if True. show_names : bool | callable If True, show channel names on top of the map. If a callable is passed, channel names will be formatted using the callable; e.g., to delete the prefix &#39;MEG &#39; from all channel names, pass the function lambda x: x.replace(&#39;MEG &#39;, &#39;&#39;). If `mask` is not None, only significant sensors will be shown. title : str | None Title. If None (default), no title is displayed. mask : ndarray of bool, shape (n_channels, n_times) | None The channels to be marked as significant at a given time point. Indices set to `True` will be considered. Defaults to None. mask_params : dict | None Additional plotting parameters for plotting significant sensors. Default (None) equals:: dict(marker=&#39;o&#39;, markerfacecolor=&#39;w&#39;, markeredgecolor=&#39;k&#39;, linewidth=0, markersize=4) outlines : &#39;head&#39; | &#39;skirt&#39; | dict | None The outlines to be drawn. If &#39;head&#39;, the default head scheme will be drawn. If &#39;skirt&#39; the head scheme will be drawn, but sensors are allowed to be plotted outside of the head circle. If dict, each key refers to a tuple of x and y positions, the values in &#39;mask_pos&#39; will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to &#39;head&#39;. contours : int | array of float The number of contour lines to draw. If 0, no contours will be drawn. When an integer, matplotlib ticker locator is used to find suitable values for the contour thresholds (may sometimes be inaccurate, use array for accuracy). If an array, the values represent the levels for the contours. The values are in µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the ticks in colorbar correspond to the contour levels. Defaults to 6. image_interp : str The image interpolation to be used. All matplotlib options are accepted. average : float | None The time window around a given time to be used for averaging (seconds). For example, 0.01 would translate into window that starts 5 ms before and ends 5 ms after a given time point. Defaults to None, which means no averaging. head_pos : dict | None Deprecated and will be removed in 0.21. Use ``sphere`` instead. axes : instance of Axes | list | None The axes to plot to. If list, the list must be a list of Axes of the same length as ``times`` (unless ``times`` is None). If instance of Axes, ``times`` must be a float or a list of one float. Defaults to None. extrapolate : str Options: - &#39;box&#39; (default) Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension. - &#39;local&#39; Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). - &#39;head&#39; Extrapolate to the edges of the head circle (does not work well with sensors outside the head circle). .. versionadded:: 0.18 sphere : float | array-like | str | None The sphere parameters to use for the cartoon head. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give the radius (origin assumed 0, 0, 0). Can also be a spherical ConductorModel, which will use the origin and radius. Can be &#34;auto&#34; to use a digitization-based fit. Can also be None (default) to use &#39;auto&#39; when enough extra digitization points are available, and 0.095 otherwise. Currently the head radius does not affect plotting. .. versionadded:: 0.20 border : float | &#39;mean&#39; Value to extrapolate to on the topomap borders. If ``&#39;mean&#39;`` then each extrapolated point has the average value of its neighbours. .. versionadded:: 0.20 nrows : int | &#39;auto&#39; The number of rows of topographies to plot. Defaults to 1. If &#39;auto&#39;, obtains the number of rows depending on the amount of times to plot and the number of cols. Not valid when times == &#39;interactive&#39;. .. versionadded:: 0.20 ncols : int | &#39;auto&#39; The number of columns of topographies to plot. If &#39;auto&#39; (default), obtains the number of columns depending on the amount of times to plot and the number of rows. Not valid when times == &#39;interactive&#39;. .. versionadded:: 0.20 Returns - fig : instance of matplotlib.figure.Figure The figure. File: c: users babib anaconda3 envs mne lib site-packages mne evoked.py Type: method . Plot Topomap . target.plot_topomap(times = [0.1, 0.2, 0.3, 0.4, 0.5]); . target.plot_joint(times = [0.1, 0.2, 0.3, 0.37, 0.5]); . For condition contrasts, you can use mne.combine.evoked: . mne.combine_evoked? . Signature: mne.combine_evoked(all_evoked, weights) Docstring: Merge evoked data by weighted addition or subtraction. Data should have the same channels and the same time instants. Subtraction can be performed by calling ``combine_evoked([evoked1, -evoked2], &#39;equal&#39;)`` .. Warning:: If you provide an array of weights instead of using `&#39;equal&#39;` or `&#39;nave&#39;`, strange things may happen with your resulting signal amplitude and/or `.nave` attribute. Parameters - all_evoked : list of Evoked The evoked datasets. weights : list of float | str The weights to apply to the data of each evoked instance. Can also be ``&#39;nave&#39;`` to weight according to evoked.nave, or ``&#34;equal&#34;`` to use equal weighting (each weighted as ``1/N``). Returns - evoked : Evoked The new evoked data. Notes -- .. versionadded:: 0.9.0 File: c: users babib anaconda3 envs mne lib site-packages mne evoked.py Type: function . Plot Joint . diff = mne.combine_evoked((target, -standard), weights=&#39;equal&#39;) diff.plot_joint(times=[0.1, 0.2, 0.3, 0.37, 0.5]); . Or as an image: . diff.plot_image(); . Because we have a 10/20 electrode layout, we can easily use a somewhat nicer layout: . rois = mne.channels.make_1020_channel_selections(diff.info, midline=&quot;z12&quot;) . rois . {&#39;Left&#39;: array([25, 57, 58, 20, 53, 21, 48, 16, 49, 12, 44, 11, 40, 7, 39, 3, 34, 2, 31, 30]), &#39;Midline&#39;: array([27, 28, 26, 59, 54, 55, 22, 17, 18, 50, 46, 13, 45, 62, 9, 8, 4, 36, 35, 1, 0, 38, 43]), &#39;Right&#39;: array([29, 61, 60, 24, 56, 23, 52, 19, 51, 14, 15, 47, 41, 10, 42, 5, 37, 6, 32, 33])} . Plot Image by the Region of Interest . diff.plot_image(group_by=rois, show=False, show_names=&quot;all&quot;); . To contrast multiple conditions, mne.viz.plot_compare_evokeds is available: . mne.viz.plot_compare_evokeds({&quot;standard&quot;: standard, &quot;target&quot;: target}, picks=[9]); . &#39;plot&#39;, &#39;plot_field&#39;, &#39;plot_image&#39;, &#39;plot_joint&#39;, &#39;plot_projs_topomap&#39;, &#39;plot_sensors&#39;, &#39;plot_topo&#39;, &#39;plot_topomap&#39;, &#39;plot_white&#39;, target.plot_topo(); . target.plot_sensors(show_names = True); . target.data . array([[-2.10035784e-07, -2.76375979e-07, -4.35090469e-07, ..., -3.15511555e-06, -2.78982956e-06, -2.65591278e-06], [-1.14376608e-06, -1.12506920e-06, -1.19371126e-06, ..., -6.47561653e-06, -6.07672040e-06, -5.82352233e-06], [ 5.98786497e-07, 3.52630830e-07, 2.33978080e-07, ..., -9.69141043e-07, -8.53105041e-07, -9.22077181e-07], ..., [-4.99535795e-08, 3.00249622e-07, 3.81435930e-07, ..., 2.44255774e-06, 1.95231303e-06, 1.41322678e-06], [-3.46014338e-08, 1.47143539e-07, 2.53983361e-07, ..., 1.59443108e-06, 1.11796711e-06, 7.14063649e-07], [-1.44211725e-06, -1.33997168e-06, -1.55426496e-06, ..., -6.17147388e-06, -5.47561990e-06, -5.17723397e-06]]) . x = target.data . ch_names = target.info[&#39;ch_names&#39;] ch_names . [&#39;FP1&#39;, &#39;FP2&#39;, &#39;F7&#39;, &#39;F3&#39;, &#39;Fz&#39;, &#39;F4&#39;, &#39;F8&#39;, &#39;FC5&#39;, &#39;FC1&#39;, &#39;FC2&#39;, &#39;FC6&#39;, &#39;T7&#39;, &#39;C3&#39;, &#39;Cz&#39;, &#39;C4&#39;, &#39;T8&#39;, &#39;CP5&#39;, &#39;CP1&#39;, &#39;CP2&#39;, &#39;CP6&#39;, &#39;P7&#39;, &#39;P3&#39;, &#39;Pz&#39;, &#39;P4&#39;, &#39;P8&#39;, &#39;PO9&#39;, &#39;O1&#39;, &#39;Oz&#39;, &#39;O2&#39;, &#39;PO10&#39;, &#39;AF7&#39;, &#39;AF3&#39;, &#39;AF4&#39;, &#39;AF8&#39;, &#39;F5&#39;, &#39;F1&#39;, &#39;F2&#39;, &#39;F6&#39;, &#39;SO1&#39;, &#39;FT7&#39;, &#39;FC3&#39;, &#39;FC4&#39;, &#39;FT8&#39;, &#39;SO2&#39;, &#39;C5&#39;, &#39;C1&#39;, &#39;C2&#39;, &#39;C6&#39;, &#39;TP7&#39;, &#39;CP3&#39;, &#39;CPz&#39;, &#39;CP4&#39;, &#39;TP8&#39;, &#39;P5&#39;, &#39;P1&#39;, &#39;P2&#39;, &#39;P6&#39;, &#39;PO7&#39;, &#39;PO3&#39;, &#39;POz&#39;, &#39;PO4&#39;, &#39;PO8&#39;, &#39;FCz&#39;] . channel = &#39;Cz&#39; chIndex = [i for i, j in enumerate(ch_names) if j == channel] . plt.plot(x.T) plt.title(channel) plt.ylabel(&quot;Amplitude&quot;) plt.xlabel(&#39;Time Samples&#39;) . Text(0.5, 0, &#39;Time Samples&#39;) . Time-Frequency stuff . For an overview over the spectral shape of the data, we can use a plotting method of raw, raw.plot_psd: . epochs_for_tfr = mne.read_epochs(&quot;oddball-long-epo.fif&quot;) . Reading oddball-long-epo.fif ... Isotrak not found Found the data of interest: t = -500.00 ... 1500.00 ms 0 CTF compensation matrices available 212 matching events found Applying baseline correction (mode: mean) Not setting metadata 0 projection items activated . plot_psd . epochs_for_tfr.plot_psd? . Signature: epochs_for_tfr.plot_psd( fmin=0, fmax=inf, tmin=None, tmax=None, proj=False, bandwidth=None, adaptive=False, low_bias=True, normalization=&#39;length&#39;, picks=None, ax=None, color=&#39;black&#39;, xscale=&#39;linear&#39;, area_mode=&#39;std&#39;, area_alpha=0.33, dB=True, estimate=&#39;auto&#39;, show=True, n_jobs=1, average=False, line_alpha=None, spatial_colors=True, sphere=None, verbose=None, ) Docstring: Plot the power spectral density across channels. Different channel types are drawn in sub-plots. When the data have been processed with a bandpass, lowpass or highpass filter, dashed lines indicate the boundaries of the filter (--). The line noise frequency is also indicated with a dashed line (-.). Parameters - fmin : float Start frequency to consider. fmax : float End frequency to consider. tmin : float | None Start time to consider. tmax : float | None End time to consider. proj : bool Apply projection. bandwidth : float The bandwidth of the multi taper windowing function in Hz. The default value is a window half-bandwidth of 4. adaptive : bool Use adaptive weights to combine the tapered spectra into PSD (slow, use n_jobs &gt;&gt; 1 to speed up computation). low_bias : bool Only use tapers with more than 90% spectral concentration within bandwidth. normalization : str Either &#34;full&#34; or &#34;length&#34; (default). If &#34;full&#34;, the PSD will be normalized by the sampling rate as well as the length of the signal (as in nitime). picks : str | list | slice | None Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel *type* strings (e.g., ``[&#39;meg&#39;, &#39;eeg&#39;]``) will pick channels of those types, channel *name* strings (e.g., ``[&#39;MEG0111&#39;, &#39;MEG2623&#39;]`` will pick the given channels. Can also be the string values &#34;all&#34; to pick all channels, or &#34;data&#34; to pick :term:`data channels`. None (default) will pick good data channels Cannot be None if `ax` is supplied.If both `picks` and `ax` are None separate subplots will be created for each standard channel type (`mag`, `grad`, and `eeg`). ax : instance of Axes | None Axes to plot into. If None, axes will be created. color : str | tuple A matplotlib-compatible color to use. Has no effect when spatial_colors=True. xscale : str Can be &#39;linear&#39; (default) or &#39;log&#39;. area_mode : str | None Mode for plotting area. If &#39;std&#39;, the mean +/- 1 STD (across channels) will be plotted. If &#39;range&#39;, the min and max (across channels) will be plotted. Bad channels will be excluded from these calculations. If None, no area will be plotted. If average=False, no area is plotted. area_alpha : float Alpha for the area. dB : bool Plot Power Spectral Density (PSD), in units (amplitude**2/Hz (dB)) if ``dB=True``, and ``estimate=&#39;power&#39;`` or ``estimate=&#39;auto&#39;``. Plot PSD in units (amplitude**2/Hz) if ``dB=False`` and, ``estimate=&#39;power&#39;``. Plot Amplitude Spectral Density (ASD), in units (amplitude/sqrt(Hz)), if ``dB=False`` and ``estimate=&#39;amplitude&#39;`` or ``estimate=&#39;auto&#39;``. Plot ASD, in units (amplitude/sqrt(Hz) (db)), if ``dB=True`` and ``estimate=&#39;amplitude&#39;``. estimate : str, {&#39;auto&#39;, &#39;power&#39;, &#39;amplitude&#39;} Can be &#34;power&#34; for power spectral density (PSD), &#34;amplitude&#34; for amplitude spectrum density (ASD), or &#34;auto&#34; (default), which uses &#34;power&#34; when dB is True and &#34;amplitude&#34; otherwise. show : bool Show figure if True. n_jobs : int The number of jobs to run in parallel (default 1). Requires the joblib package. average : bool If False, the PSDs of all channels is displayed. No averaging is done and parameters area_mode and area_alpha are ignored. When False, it is possible to paint an area (hold left mouse button and drag) to plot a topomap. line_alpha : float | None Alpha for the PSD line. Can be None (default) to use 1.0 when ``average=True`` and 0.1 when ``average=False``. spatial_colors : bool Whether to use spatial colors. Only used when ``average=False``. sphere : float | array-like | str | None The sphere parameters to use for the cartoon head. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give the radius (origin assumed 0, 0, 0). Can also be a spherical ConductorModel, which will use the origin and radius. Can be &#34;auto&#34; to use a digitization-based fit. Can also be None (default) to use &#39;auto&#39; when enough extra digitization points are available, and 0.095 otherwise. Currently the head radius does not affect plotting. .. versionadded:: 0.20 verbose : bool, str, int, or None If not None, override default verbose level (see :func:`mne.verbose` and :ref:`Logging documentation &lt;tut_logging&gt;` for more). Returns - fig : instance of Figure Figure with frequency spectra of the data channels. File: c: users babib anaconda3 envs mne lib site-packages mne epochs.py Type: method . epochs_for_tfr.info . &lt;Info | 10 non-empty values bads: [] ch_names: FP1, FP2, F7, F3, Fz, F4, F8, FC5, FC1, FC2, FC6, T7, C3, Cz, ... chs: 63 EEG, 1 STIM custom_ref_applied: True file_id: 4 items (dict) highpass: 1.0 Hz lowpass: 20.0 Hz meas_date: 2017-08-10 20:05:16 UTC meas_id: 4 items (dict) nchan: 64 projs: [] sfreq: 100.0 Hz &gt; . epochs_for_tfr.plot_psd(fmin=0, fmax=40); . Using multitaper spectrum estimation with 7 DPSS windows . But what about the time/frequency correlates of the Oddball effect? . We will extract power per time and frequency with Morlet wavelets. . from mne.time_frequency import tfr_morlet . mne.time_frequency.tfr_morlet? . Signature: mne.time_frequency.tfr_morlet( inst, freqs, n_cycles, use_fft=False, return_itc=True, decim=1, n_jobs=1, picks=None, zero_mean=True, average=True, output=&#39;power&#39;, verbose=None, ) Docstring: Compute Time-Frequency Representation (TFR) using Morlet wavelets. Parameters - inst : Epochs | Evoked The epochs or evoked object. freqs : ndarray, shape (n_freqs,) The frequencies in Hz. n_cycles : float | ndarray, shape (n_freqs,) The number of cycles globally or for each frequency. use_fft : bool, default False The fft based convolution or not. return_itc : bool, default True Return inter-trial coherence (ITC) as well as averaged power. Must be ``False`` for evoked data. decim : int | slice, default 1 To reduce memory usage, decimation factor after time-frequency decomposition. If `int`, returns tfr[..., ::decim]. If `slice`, returns tfr[..., decim]. .. note:: Decimation may create aliasing artifacts. n_jobs : int The number of jobs to run in parallel (default 1). Requires the joblib package. picks : array-like of int | None, default None The indices of the channels to decompose. If None, all available good data channels are decomposed. zero_mean : bool, default True Make sure the wavelet has a mean of zero. .. versionadded:: 0.13.0 average : bool, default True If True average across Epochs. .. versionadded:: 0.13.0 output : str Can be &#34;power&#34; (default) or &#34;complex&#34;. If &#34;complex&#34;, then average must be False. .. versionadded:: 0.15.0 verbose : bool, str, int, or None If not None, override default verbose level (see :func:`mne.verbose` and :ref:`Logging documentation &lt;tut_logging&gt;` for more). Returns - power : AverageTFR | EpochsTFR The averaged or single-trial power. itc : AverageTFR | EpochsTFR The inter-trial coherence (ITC). Only returned if return_itc is True. See Also -- mne.time_frequency.tfr_array_morlet mne.time_frequency.tfr_multitaper mne.time_frequency.tfr_array_multitaper mne.time_frequency.tfr_stockwell mne.time_frequency.tfr_array_stockwell File: c: users babib anaconda3 envs mne lib site-packages mne time_frequency tfr.py Type: function . freqs = list(range(3, 30)) tfr_target = tfr_morlet(epochs_for_tfr[&quot;target&quot;], freqs, 3, return_itc=False) tfr_standard = tfr_morlet(epochs_for_tfr[&quot;standard&quot;], freqs, 3, return_itc=False) . tfr_target.data.shape . (63, 27, 201) . Time-frequency data (single trial or averaged) is stored in TFR objects. These objects behave in many ways like Evoked objects ... . tfr_contrast = mne.combine_evoked((tfr_standard, tfr_target), (-.5, .5)) tfr_contrast.apply_baseline((None, 0)) . Applying baseline correction (mode: mean) . &lt;AverageTFR | time : [-0.500000, 1.500000], freq : [3.000000, 29.000000], nave : 212, channels : 63, ~2.7 MB&gt; . Plotting time-frequencyy activity (event-related spectral perturbations): observe the alpha-band ERD and the time-frequency correlates of the P3 effect. . tfr_contrast.plot_joint(); . No baseline correction applied No baseline correction applied . tfr_contrast.plot(picks=[13]); . No baseline correction applied .",
            "url": "https://berdakh.github.io/blog/eeg/jupyter/2020/09/14/MNE-Tutorial-part-2.html",
            "relUrl": "/eeg/jupyter/2020/09/14/MNE-Tutorial-part-2.html",
            "date": " • Sep 14, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "MNE tutorial part 1",
            "content": "from IPython.display import YouTubeVideo YouTubeVideo(&#39;qb9ngu62Fbw&#39;, width=800, height=400) . %matplotlib inline import mne import matplotlib.pyplot as plt . fname = &quot;oddball_example_small-fif.gz&quot; . Read in raw data; raw objects . raw = mne.io.read_raw_fif(fname) . Opening raw data file oddball_example_small-fif.gz... . &lt;ipython-input-4-78767f98f250&gt;:1: RuntimeWarning: This filename (oddball_example_small-fif.gz) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz or _meg.fif raw = mne.io.read_raw_fif(fname) . Isotrak not found Range : 2903 ... 112000 = 29.030 ... 1120.000 secs Ready. . Visualize sample data . raw.plot(duration=60.0, start=0.0, n_channels=16,); . The information about the object can be found at raw.info . print(raw.info) . &lt;Info | 10 non-empty values bads: [] ch_names: FP1, FP2, F7, F3, Fz, F4, F8, FC5, FC1, FC2, FC6, T7, C3, Cz, ... chs: 63 EEG, 1 STIM custom_ref_applied: True file_id: 4 items (dict) highpass: 0.1 Hz lowpass: 30.0 Hz meas_date: 2017-08-10 20:05:16 UTC meas_id: 4 items (dict) nchan: 64 projs: [] sfreq: 100.0 Hz &gt; . MNE is object oriented. Objects have corresponding methods. Check which by typing raw. and pressing TAB: . raw.filter . &lt;bound method BaseRaw.filter of &lt;Raw | oddball_example_small-fif.gz, 64 x 109098 (1091.0 s), ~120 kB, data not loaded&gt;&gt; . raw.resample raw.filter raw.drop_channels ... . Can we do further preprocessing?.. . raw.filter(1, 20) . RuntimeError Traceback (most recent call last) &lt;ipython-input-8-780629dd327e&gt; in &lt;module&gt; -&gt; 1 raw.filter(1, 20) ~ anaconda3 envs mne lib site-packages mne io base.py in filter(self, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, phase, fir_window, fir_design, skip_by_annotation, pad, verbose) 926 skip_by_annotation=(&#39;edge&#39;, &#39;bad_acq_skip&#39;), 927 pad=&#39;reflect_limited&#39;, verbose=None): # noqa: D102 --&gt; 928 return super().filter( 929 l_freq, h_freq, picks, filter_length, l_trans_bandwidth, 930 h_trans_bandwidth, n_jobs, method, iir_params, phase, &lt;decorator-gen-111&gt; in filter(self, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, phase, fir_window, fir_design, skip_by_annotation, pad, verbose) ~ anaconda3 envs mne lib site-packages mne filter.py in filter(self, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, phase, fir_window, fir_design, skip_by_annotation, pad, verbose) 1920 &#34;&#34;&#34; 1921 from .io.base import BaseRaw -&gt; 1922 _check_preload(self, &#39;inst.filter&#39;) 1923 if pad is None and method != &#39;iir&#39;: 1924 pad = &#39;edge&#39; ~ anaconda3 envs mne lib site-packages mne utils check.py in _check_preload(inst, msg) 187 name = &#34;epochs&#34; if isinstance(inst, BaseEpochs) else &#39;raw&#39; 188 if not inst.preload: --&gt; 189 raise RuntimeError( 190 &#34;By default, MNE does not load data into main memory to &#34; 191 &#34;conserve resources. &#34; + msg + &#39; requires %s data to be &#39; RuntimeError: By default, MNE does not load data into main memory to conserve resources. inst.filter requires raw data to be loaded. Use preload=True (or string) in the constructor or raw.load_data(). . By default, MNE does not store raw and epochs objects in memory. . raw = mne.io.read_raw_fif(fname, preload=True) . Opening raw data file oddball_example_small-fif.gz... . &lt;ipython-input-9-7341ee706cdd&gt;:1: RuntimeWarning: This filename (oddball_example_small-fif.gz) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz or _meg.fif raw = mne.io.read_raw_fif(fname, preload=True) . Isotrak not found Range : 2903 ... 112000 = 29.030 ... 1120.000 secs Ready. Reading 0 ... 109097 = 0.000 ... 1090.970 secs... . raw.filter(1, 20) . Filtering raw data in 1 contiguous segment Setting up band-pass filter from 1 - 20 Hz FIR filter parameters Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 1.00 - Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz) - Upper passband edge: 20.00 Hz - Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz) - Filter length: 331 samples (3.310 sec) . &lt;Raw | oddball_example_small-fif.gz, 64 x 109098 (1091.0 s), ~53.4 MB, data loaded&gt; . Inspecting raw data ... . raw.plot(duration=60.0, start=0.0, n_channels=16,); . There are many eog artefacts. We will use ICA to correct these. For this, we create an ICA object and use its .fit method on a filtered copy of the raw data: . ICA decomposition . ica = mne.preprocessing.ICA(n_components=20, random_state=0) . ica.fit(raw.copy().filter(8, 35)) . Filtering raw data in 1 contiguous segment Setting up band-pass filter from 8 - 35 Hz FIR filter parameters Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 8.00 - Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz) - Upper passband edge: 35.00 Hz - Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz) - Filter length: 165 samples (1.650 sec) Fitting ICA to data using 63 channels (please be patient, this may take a while) Inferring max_pca_components from picks Selecting by number: 20 components Fitting ICA took 6.9s. . &lt;ICA | raw data decomposition, fit (fastica): 109098 samples, 20 components, channels used: &#34;eeg&#34;&gt; . ica.plot_components(outlines=&quot;skirt&quot;); . We store &quot;bad&quot; components in the ica object. . ica.exclude = [1, 10, 14, 17, 18, 19] . We could also use one of the automatic algorithms ... . bad_idx, scores = ica.find_bads_eog(raw, &#39;SO2&#39;, threshold=2) print(bad_idx) . Using channel SO2 as EOG channel ... filtering ICA sources Setting up band-pass filter from 1 - 10 Hz FIR filter parameters Designing a two-pass forward and reverse, zero-phase, non-causal bandpass filter: - Windowed frequency-domain design (firwin2) method - Hann window - Lower passband edge: 1.00 - Lower transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 0.75 Hz) - Upper passband edge: 10.00 Hz - Upper transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 10.25 Hz) - Filter length: 1024 samples (10.240 sec) ... filtering target Setting up band-pass filter from 1 - 10 Hz FIR filter parameters Designing a two-pass forward and reverse, zero-phase, non-causal bandpass filter: - Windowed frequency-domain design (firwin2) method - Hann window - Lower passband edge: 1.00 - Lower transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 0.75 Hz) - Upper passband edge: 10.00 Hz - Upper transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 10.25 Hz) - Filter length: 1024 samples (10.240 sec) [14, 10] . Let&#39;s compare raw and corrected data ... . Before ICA plot . raw.plot(duration=60.0, start=0.0, n_channels=16,); . After ICA plot . ica.apply(raw.copy(), exclude=ica.exclude).plot(duration=60.0, start=0.0, n_channels=16); . Transforming to ICA space (20 components) Zeroing out 6 ICA components . Epochs . For epoching the data, we need event markers. Usually, these are stored in the raw object; in MNE, in a stimulus channel. . mne.find_events? . Signature: mne.find_events( raw, stim_channel=None, output=&#39;onset&#39;, consecutive=&#39;increasing&#39;, min_duration=0, shortest_event=2, mask=None, uint_cast=False, mask_type=&#39;and&#39;, initial_event=False, verbose=None, ) Docstring: Find events from raw file. See :ref:`tut-events-vs-annotations` and :ref:`tut-event-arrays` for more information about events. Parameters - raw : Raw object The raw data. stim_channel : None | str | list of str Name of the stim channel or all the stim channels affected by triggers. If None, the config variables &#39;MNE_STIM_CHANNEL&#39;, &#39;MNE_STIM_CHANNEL_1&#39;, &#39;MNE_STIM_CHANNEL_2&#39;, etc. are read. If these are not found, it will fall back to &#39;STI 014&#39; if present, then fall back to the first channel of type &#39;stim&#39;, if present. If multiple channels are provided then the returned events are the union of all the events extracted from individual stim channels. output : &#39;onset&#39; | &#39;offset&#39; | &#39;step&#39; Whether to report when events start, when events end, or both. consecutive : bool | &#39;increasing&#39; If True, consider instances where the value of the events channel changes without first returning to zero as multiple events. If False, report only instances where the value of the events channel changes from/to zero. If &#39;increasing&#39;, report adjacent events only when the second event code is greater than the first. min_duration : float The minimum duration of a change in the events channel required to consider it as an event (in seconds). shortest_event : int Minimum number of samples an event must last (default is 2). If the duration is less than this an exception will be raised. mask : int | None The value of the digital mask to apply to the stim channel values. If None (default), no masking is performed. uint_cast : bool If True (default False), do a cast to ``uint16`` on the channel data. This can be used to fix a bug with STI101 and STI014 in Neuromag acquisition setups that use channel STI016 (channel 16 turns data into e.g. -32768), similar to ``mne_fix_stim14 --32`` in MNE-C. .. versionadded:: 0.12 mask_type : &#39;and&#39; | &#39;not_and&#39; The type of operation between the mask and the trigger. Choose &#39;and&#39; (default) for MNE-C masking behavior. .. versionadded:: 0.13 initial_event : bool If True (default False), an event is created if the stim channel has a value different from 0 as its first sample. This is useful if an event at t=0s is present. .. versionadded:: 0.16 verbose : bool, str, int, or None If not None, override default verbose level (see :func:`mne.verbose` and :ref:`Logging documentation &lt;tut_logging&gt;` for more). Returns - events : array, shape = (n_events, 3) All events that were found. The first column contains the event time in samples and the third column contains the event id. For output = &#39;onset&#39; or &#39;step&#39;, the second column contains the value of the stim channel immediately before the event/step. For output = &#39;offset&#39;, the second column contains the value of the stim channel after the event offset. See Also -- find_stim_steps : Find all the steps in the stim channel. read_events : Read events from disk. write_events : Write events to disk. Notes -- .. warning:: If you are working with downsampled data, events computed before decimation are no longer valid. Please recompute your events after decimation, but note this reduces the precision of event timing. Examples -- Consider data with a stim channel that looks like:: [0, 32, 32, 33, 32, 0] By default, find_events returns all samples at which the value of the stim channel increases:: &gt;&gt;&gt; print(find_events(raw)) # doctest: +SKIP [[ 1 0 32] [ 3 32 33]] If consecutive is False, find_events only returns the samples at which the stim channel changes from zero to a non-zero value:: &gt;&gt;&gt; print(find_events(raw, consecutive=False)) # doctest: +SKIP [[ 1 0 32]] If consecutive is True, find_events returns samples at which the event changes, regardless of whether it first returns to zero:: &gt;&gt;&gt; print(find_events(raw, consecutive=True)) # doctest: +SKIP [[ 1 0 32] [ 3 32 33] [ 4 33 32]] If output is &#39;offset&#39;, find_events returns the last sample of each event instead of the first one:: &gt;&gt;&gt; print(find_events(raw, consecutive=True, # doctest: +SKIP ... output=&#39;offset&#39;)) [[ 2 33 32] [ 3 32 33] [ 4 0 32]] If output is &#39;step&#39;, find_events returns the samples at which an event starts or ends:: &gt;&gt;&gt; print(find_events(raw, consecutive=True, # doctest: +SKIP ... output=&#39;step&#39;)) [[ 1 0 32] [ 3 32 33] [ 4 33 32] [ 5 32 0]] To ignore spurious events, it is also possible to specify a minimum event duration. Assuming our events channel has a sample rate of 1000 Hz:: &gt;&gt;&gt; print(find_events(raw, consecutive=True, # doctest: +SKIP ... min_duration=0.002)) [[ 1 0 32]] For the digital mask, if mask_type is set to &#39;and&#39; it will take the binary representation of the digital mask, e.g. 5 -&gt; &#39;00000101&#39;, and will allow the values to pass where mask is one, e.g.:: 7 &#39;0000111&#39; &lt;- trigger value 37 &#39;0100101&#39; &lt;- mask - 5 &#39;0000101&#39; For the digital mask, if mask_type is set to &#39;not_and&#39; it will take the binary representation of the digital mask, e.g. 5 -&gt; &#39;00000101&#39;, and will block the values where mask is one, e.g.:: 7 &#39;0000111&#39; &lt;- trigger value 37 &#39;0100101&#39; &lt;- mask - 2 &#39;0000010&#39; File: c: users babib anaconda3 envs mne lib site-packages mne event.py Type: function . events = mne.find_events(raw) . 903 events found Event IDs: [100 200] . events is simply an array (time in samples, zero, trigger); . events . array([[ 3241, 0, 200], [ 3437, 0, 200], [ 3643, 0, 200], ..., [111496, 0, 200], [111613, 0, 200], [111719, 0, 200]], dtype=int64) . ... which we can visualize: . plt.rcParams[&#39;figure.figsize&#39;] = [10, 5] . mne.viz.plot_events(events[:100]); . For creating an mne.Epochs object, we require, in addition to the raw object and the events array, a dictionary of the intended condition names and the corresponding trigger numbers. . event_ids = {&quot;standard/stimulus&quot;: 200, &quot;target/stimulus&quot;: 100} epochs = mne.Epochs(raw, events, event_id=event_ids) . 903 matching events found Applying baseline correction (mode: mean) Not setting metadata 0 projection items activated . epochs.plot(); . Loading data for 903 events and 71 original time points ... 0 bad epochs dropped Loading data for 903 events and 71 original time points ... Loading data for 20 events and 71 original time points ... . (changing to the inline backend now to speed things up.) . epochs = ica.apply(epochs, exclude=ica.exclude) . RuntimeError Traceback (most recent call last) &lt;ipython-input-26-6221a76f7f3f&gt; in &lt;module&gt; -&gt; 1 epochs = ica.apply(epochs, exclude=ica.exclude) ~ anaconda3 envs mne lib site-packages mne preprocessing ica.py in apply(self, inst, include, exclude, n_pca_components, start, stop) 1405 _check_compensation_grade(self.info, inst.info, &#39;ICA&#39;, kind, 1406 ch_names=self.ch_names) -&gt; 1407 return meth(**kwargs) 1408 1409 def _check_exclude(self, exclude): ~ anaconda3 envs mne lib site-packages mne preprocessing ica.py in _apply_epochs(self, epochs, include, exclude, n_pca_components) 1436 def _apply_epochs(self, epochs, include, exclude, n_pca_components): 1437 &#34;&#34;&#34;Aux method.&#34;&#34;&#34; -&gt; 1438 _check_preload(epochs, &#34;ica.apply&#34;) 1439 1440 picks = pick_types(epochs.info, meg=False, ref_meg=False, ~ anaconda3 envs mne lib site-packages mne utils check.py in _check_preload(inst, msg) 187 name = &#34;epochs&#34; if isinstance(inst, BaseEpochs) else &#39;raw&#39; 188 if not inst.preload: --&gt; 189 raise RuntimeError( 190 &#34;By default, MNE does not load data into main memory to &#34; 191 &#34;conserve resources. &#34; + msg + &#39; requires %s data to be &#39; RuntimeError: By default, MNE does not load data into main memory to conserve resources. ica.apply requires epochs data to be loaded. Use preload=True (or string) in the constructor or epochs.load_data(). . Of course ... . epochs = mne.Epochs(raw, events, event_id=event_ids, preload=True) epochs = ica.apply(epochs, exclude=ica.exclude) . 903 matching events found Applying baseline correction (mode: mean) Not setting metadata 0 projection items activated Loading data for 903 events and 71 original time points ... 0 bad epochs dropped Transforming to ICA space (20 components) Zeroing out 6 ICA components . The mne.Epochs constructor has a number of options, such as time window lengths and rejection thresholds. Investigate them on your own. . Epochs objects also have various methods, different from raw objects - e.g., for baselining. . epochs.apply_baseline((None, 0)) . Applying baseline correction (mode: mean) . &lt;Epochs | 903 events (all good), -0.2 - 0.5 sec, baseline [None, 0], ~31.4 MB, data loaded, &#39;standard/stimulus&#39;: 797 &#39;target/stimulus&#39;: 106&gt; . ... and many more ... . epochs. . File &#34;&lt;ipython-input-29-0e32a7ceced3&gt;&#34;, line 1 epochs. ^ SyntaxError: invalid syntax . To subselect only a sample of epochs, a dict-like access mode is available. . epochs . &lt;Epochs | 903 events (all good), -0.2 - 0.5 sec, baseline [None, 0], ~31.4 MB, data loaded, &#39;standard/stimulus&#39;: 797 &#39;target/stimulus&#39;: 106&gt; . epochs[&quot;target&quot;] . &lt;Epochs | 106 events (all good), -0.2 - 0.5 sec, baseline [None, 0], ~3.8 MB, data loaded, &#39;target/stimulus&#39;: 106&gt; . Observe how tags selected by forward slashes - &quot;/&quot; - work. . epochs[&quot;stimulus&quot;] . &lt;Epochs | 903 events (all good), -0.2 - 0.5 sec, baseline [None, 0], ~31.4 MB, data loaded, &#39;standard/stimulus&#39;: 797 &#39;target/stimulus&#39;: 106&gt; . How does the epoched activity look like? . epochs.info . &lt;Info | 10 non-empty values bads: [] ch_names: FP1, FP2, F7, F3, Fz, F4, F8, FC5, FC1, FC2, FC6, T7, C3, Cz, ... chs: 63 EEG, 1 STIM custom_ref_applied: True file_id: 4 items (dict) highpass: 1.0 Hz lowpass: 20.0 Hz meas_date: 2017-08-10 20:05:16 UTC meas_id: 4 items (dict) nchan: 64 projs: [] sfreq: 100.0 Hz &gt; . epochs[&quot;target&quot;].plot_image(picks=[13]); . 106 matching events found No baseline correction applied Not setting metadata 0 projection items activated 0 bad epochs dropped . To ensure we have as many Oddball as Standard trials, we can run ... . epochs.equalize_event_counts(event_ids) epochs . Dropped 691 epochs: 0, 1, 2, 3, 4, 5, 6, 9, 12, 13, 14, 15, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 72, 73, 74, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 107, 108, 109, 110, 113, 114, 115, 116, 117, 118, 121, 122, 123, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 146, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 187, 188, 193, 194, 197, 198, 199, 200, 201, 202, 203, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 248, 249, 252, 253, 254, 257, 260, 261, 262, 263, 266, 267, 268, 269, 270, 271, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 290, 291, 292, 295, 296, 297, 298, 299, 300, 301, 302, 303, 306, 307, 308, 309, 310, 311, 312, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 343, 344, 345, 346, 347, 348, 349, 350, 353, 354, 355, 358, 359, 360, 361, 362, 363, 364, 365, 368, 369, 370, 371, 372, 375, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 432, 433, 434, 435, 438, 439, 442, 449, 450, 451, 452, 453, 458, 459, 464, 465, 466, 467, 472, 473, 474, 475, 476, 477, 482, 483, 484, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 546, 547, 548, 551, 552, 553, 554, 555, 558, 559, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 610, 611, 612, 615, 616, 619, 620, 621, 624, 625, 626, 627, 628, 629, 630, 631, 632, 635, 636, 637, 638, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 674, 675, 676, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 780, 781, 782, 785, 786, 787, 788, 791, 792, 793, 794, 795, 796, 799, 802, 805, 806, 809, 810, 811, 812, 813, 814, 817, 818, 821, 822, 823, 826, 827, 828, 829, 830, 831, 832, 833, 834, 837, 838, 839, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 872, 875, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902 . &lt;Epochs | 212 events (all good), -0.2 - 0.5 sec, baseline [None, 0], ~7.5 MB, data loaded, &#39;standard/stimulus&#39;: 106 &#39;target/stimulus&#39;: 106&gt; . We can write the Epochs object to disk so we don&#39;t have to repeat the preprocessing later ... . Save data . epochs.save(&quot;oddball2-epo.fif&quot;) # remember, the data has been cleaned of bad ICs . epochs_for_tfr = mne.Epochs(raw, events, event_id=event_ids, tmin=-.5, tmax=1.5, preload=True) # need longer data segment . 903 matching events found Applying baseline correction (mode: mean) Not setting metadata 0 projection items activated Loading data for 903 events and 201 original time points ... 0 bad epochs dropped . epochs_for_tfr.plot(); . epochs_for_tfr = ica.apply(epochs_for_tfr, exclude=ica.exclude) epochs_for_tfr.equalize_event_counts(event_ids); # to speed up things #epochs_for_tfr.save(&quot;oddball-long-epo.fif&quot;) . Transforming to ICA space (20 components) Zeroing out 6 ICA components Dropped 0 epochs: . Get Numpy Array . X = epochs.get_data() . X.shape . (212, 64, 71) . type(X) . numpy.ndarray . epochs[&#39;target&#39;].get_data().shape . (106, 64, 71) . Xtarget = epochs[&#39;target&#39;].get_data() Xnontarget = epochs[&#39;standard&#39;].get_data() . Xtarget.shape . (106, 64, 71) . Xnontarget.shape . (106, 64, 71) .",
            "url": "https://berdakh.github.io/blog/eeg/jupyter/2020/09/10/MNE-Tutorial.html",
            "relUrl": "/eeg/jupyter/2020/09/10/MNE-Tutorial.html",
            "date": " • Sep 10, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "EEG Visualization using MNE",
            "content": "import matplotlib.pyplot as plt import numpy as np . %matplotlib inline %load_ext autoreload %autoreload 2 #%matplotlib qt . plt.rcParams[&#39;font.size&#39;] = 12 #plt.style.use(&#39;ggplot&#39;) plt.rcParams[&quot;axes.grid&quot;] = True c = plt.rcParams[&#39;axes.prop_cycle&#39;].by_key()[&#39;color&#39;] plt.rcParams[&#39;figure.figsize&#39;] = 8, 4 . from nu_smrutils import loaddat . dname = dict(BNCI2014004 = &#39;aBNCI2014004R.pickle&#39;, BNCI2014001 = &#39;aBNCI2014001R.pickle&#39;, Weibo2014 = &#39;aWeibo2014R.pickle&#39;, Physionet = &#39;aPhysionetRR.pickle&#39;) . Load data . Load EEG data for visualization . # itemname is one of : [&#39;BNCI2014004&#39;, &#39;BNCI2014001&#39;, &#39;Weibo2014&#39;, &#39;Physionet&#39;] itemname = &#39;BNCI2014001&#39; . filename = dname[itemname] iname = itemname + &#39;__&#39; data = loaddat(filename) print(&#39;Number of subjects in data :&#39;, len(data)) . Number of subjects in data : 9 . # select data from on subject and use it for demostration subject = 0 s1 = data[subject] print(s1) . &lt;Epochs | 288 events (all good), 2 - 6 sec, baseline off, ~15.6 MB, data loaded, &#39;left_hand&#39;: 144 &#39;right_hand&#39;: 144&gt; . s1[&#39;right_hand&#39;].plot(); . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; s1[&#39;right_hand&#39;].plot_psd(fmin=0, fmax=45); . Using multitaper spectrum estimation with 7 DPSS windows . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; Apply common-average reference . # use the average of all channels as reference s1.set_eeg_reference(ref_channels=&#39;average&#39;) s1[&#39;right_hand&#39;].plot(); . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; s1[&#39;right_hand&#39;].plot_psd(fmin=0, fmax=45); . Using multitaper spectrum estimation with 7 DPSS windows . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; Data info . print(s1.info) . &lt;Info | 17 non-empty fields bads : list | 0 items ch_names : list | Fz, FC3, FC1, FCz, FC2, FC4, C5, C3, C1, ... chs : list | 22 items (EEG: 22) comps : list | 0 items custom_ref_applied : bool | True dev_head_t : Transform | 3 items dig : list | 25 items (3 Cardinal, 22 EEG) events : list | 0 items highpass : float | 4.0 Hz hpi_meas : list | 0 items hpi_results : list | 0 items lowpass : float | 60.0 Hz meas_date : NoneType | unspecified nchan : int | 22 proc_history : list | 0 items projs : list | 0 items sfreq : float | 80.0 Hz acq_pars : NoneType acq_stim : NoneType ctf_head_t : NoneType description : NoneType dev_ctf_t : NoneType experimenter : NoneType file_id : NoneType gantry_angle : NoneType hpi_subsystem : NoneType kit_system_id : NoneType line_freq : NoneType meas_id : NoneType proj_id : NoneType proj_name : NoneType subject_info : NoneType xplotter_layout : NoneType &gt; . s1.plot_sensors(title = &#39;EEG sensor locations and labels&#39;, show_names = True); . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; Band-pass filter . Apply band-pass filter to extract $ mu$ and $ beta$ band EEG features between (8 - 30) Hz . s1.filter(l_freq = 8, h_freq = 30) . &lt;Epochs | 288 events (all good), 2 - 6 sec, baseline off, ~15.6 MB, data loaded, &#39;left_hand&#39;: 144 &#39;right_hand&#39;: 144&gt; . s1[&#39;right_hand&#39;].plot(); . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; s1[&#39;right_hand&#39;].plot_image(picks = [&#39;Cz&#39;], scalings = dict(eeg=1e6)) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; [&lt;Figure size 576x288 with 4 Axes&gt;] . s1[&#39;right_hand&#39;].plot_psd(fmin=0, fmax=45); . Using multitaper spectrum estimation with 7 DPSS windows . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; bands = [(4, 8, &#39;Theta&#39;), (8, 12, &#39;Mu Rhythm&#39;), (12, 30, &#39;Beta&#39;)] . s1[&#39;right_hand&#39;].plot_psd_topomap(bands = bands, normalize = True); . Using multitaper spectrum estimation with 7 DPSS windows . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; Get numpy array and visualize . print(&#39;EEG data is 3D numpy array (trials x channels x time samples) :&#39;, s1[&#39;right_hand&#39;].get_data().shape) . EEG data is 3D numpy array (trials x channels x time samples) : (144, 22, 321) . trial = 1 x = s1[&#39;right_hand&#39;].get_data()[trial,:,:] print(&#39;Channel x time samples :&#39;, x.shape) . Channel x time samples : (22, 321) . Plot single channel data from one trial . ch_names = s1.info[&#39;ch_names&#39;] ch_names . [&#39;Fz&#39;, &#39;FC3&#39;, &#39;FC1&#39;, &#39;FCz&#39;, &#39;FC2&#39;, &#39;FC4&#39;, &#39;C5&#39;, &#39;C3&#39;, &#39;C1&#39;, &#39;Cz&#39;, &#39;C2&#39;, &#39;C4&#39;, &#39;C6&#39;, &#39;CP3&#39;, &#39;CP1&#39;, &#39;CPz&#39;, &#39;CP2&#39;, &#39;CP4&#39;, &#39;P1&#39;, &#39;Pz&#39;, &#39;P2&#39;, &#39;POz&#39;] . # which channel to plot? channel = &#39;C4&#39; chIndex = [i for i, j in enumerate(ch_names) if j == channel] . plt.plot(x[chIndex[0], :]) plt.title(channel) plt.ylabel(&#39;Amplitude&#39;) plt.xlabel(&#39;Time samples&#39;) . Text(0.5, 0, &#39;Time samples&#39;) .",
            "url": "https://berdakh.github.io/blog/eeg/jupyter/2020/09/01/EEG-Visualization.html",
            "relUrl": "/eeg/jupyter/2020/09/01/EEG-Visualization.html",
            "date": " • Sep 1, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://berdakh.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About me",
          "content": "Berdakh Abibullaev, Ph.D. . . Robotics and Mechatronics Department, School of Engineering and Digital Sciences, Nazarbayev University Address: 53 Kabanbay Batyr Avenue, Nur-Sultan, Kazakhstan, Block 7. Email : berdakh.abibullaev at nu.edu.kz  . Short Biography: . . Dr. Berdakh Abibullaev received his M.Sc. and Ph.D. degrees in electronic engineering from Yeungnam University, South Korea in 2006 and 2010 under the Korean Government Scholarship program. He held research scientist positions at Daegu-Gyeongbuk Institute of Science and Technology (2010-2013) and Samsung Medical Center, South Korea (2013-2014). He was also appointed as a research professor at Sungkyunkwan University, Seoul. In 2014, he received NIH (National Institute of Health, USA), a postdoctoral research fellowship to join a research project between the University of Houston Brain-Machine Interface Systems Team and a Texas Medical Center in developing neural interfaces for rehabilitation in post-stroke patients. Currently, he is an Assistant Professor in the Department of Robotics and Mechatronics, Nazarbayev University, Kazakhstan. . Dr. Abibullaev has considerable research and clinical experience working with patient populations and physicians in applying scientific and technical skills to advance the development of treatments for neurological disorders. His current research focuses on designing robust neural-interfaces to control a robotic device for human augmentation, and advancing machine learning algorithms to develop new and alternative solutions to inference problems of Brain-Computer/Machine Interfaces. . Research Interests . . Neural Engineering: Brain-Computer/Machine Interfaces; Biomedical data analysis; Epilepsy Research; Stroke Rehabilitation, EEG/ECoG/fNIRS Signal Processing. . Machine Learning: Deep Learning and its applications; Kernel based learning; Feature Representation Learning; Pattern analysis and recognition. . Education . . PhD, Department of Electronic Engineering: {2006-2010}, Yeungnam University, South Korea . MSc, Department of Electronic Engineering: {2004-2006}, Yeungnam University, South Korea . BSc, Information and Communication Engineering: {2000-2004}, Tashkent University of Information Technologies, Uzbekistan . Academic and Research Experience . . Assistant Professor {09/2015-present}, Robotics &amp; Mechatronics Department, School of Engineering and Digital Sciences, Nazarbayev University, Nur-Sultan, Kazakhstan . Visiting Professor: {5/2018 - 7/2018}, Department of Electrical Engineering &amp; Computer Science, University of Houston, Houston, Texas, U.S.A. . NIH Postdoctoral Research Fellow II: {5/2014 - 9/2015}, Department of Electrical Engineering &amp; Computer Science, University of Houston, Houston, Texas, U.S.A. . Research Professor: {1/2014 - 9/2015}, Department of Neurology, Samsung Medical Center, Sungkyunkwan University, Seoul, South Korea . Senior Research Scientist: {05/2011 - 12/2013}, Robotics Research Division, Daegu Gyeongbuk Institute of Science and Technology, South Korea . Postdoctoral Research Fellow: {02/2010 - 05/2011}, Robotics Research Division, Daegu Gyeongbuk Institute of Science and Technology, South Korea . Selected Publications . . Check out his:: Google scholar :: for recent publications. . B. Abibullaev, I. and A. Zollanvari. A Brute-force CNN Model Selection for Accurate Classification of Sensorimotor Rhythms in BCIs IEEE Access, 2020, in press, (Impact Factor: 4; Quartile rank: Q1). . A. Zollanvari, M. Abdirash, A. Dadlani and B. Abibullaev. Asymptotically Bias-Corrected Regularized Linear Discriminant Analysis for Cost-Sensitive Binary Classification IEEE Signal Processing Letters, 2019, (Impact Factor: 2.8; Quartile rank: Q1). . B. Abibullaev and A. Zollanvari. Learning Discriminative Spatiospectral Features of ERPs for Accurate Brain-Computer Interfaces IEEE Journal of Biomedical and Health Informatics, vol. 98, pp. 1-12, 2019; (Impact Factor: 5; Quartile rank: Q1). . B. Abibullaev, A. Zollanvari, B. Saduanov, and T. Alizadeh. Design and Optimization of a BCI-Driven Telepresence Robot Through Programming by Demonstration. IEEE Access, 2019, vol. 7, (Impact Factor: 4; Quartile rank: Q1). . N.A. Bhagat, A. Venkatakrishnan, B. Abibullaev, E.J. Artz, N. Yozbatiran, A. Blank, J. French, C. Karmonik, R.G.Grossman, M.K O’Malley, G. Francisco, J.L. Contreras-Vidal. Design and optimization of an EEG-based brain machine interface (BMI) to an upper-limb exoskeleton for stroke survivors. , vol. 10, March, 2016 (Impact Factor: 3.566; Quartile rank: Q1). . J.G. Cruz-Garza, Z.R. Hernandez, T. Tse, E. Caducoy, B. Abibullaev, J.L. Contreras-Vidal. A novel experimental and analytical approach to the multimodal neural decoding of intent during social interaction in freely-behaving human infants. , doi: 10.3791/53406, October, 2015 (Impact Factor : 1.232; Quartile rank: Q2). . C.H. Park, J.H Seo, D. Kim, B. Abibullaev, H. Kwon, Y.H. Lee, M.Y. Kim, K. Kim, J.S. Kim, E.Y. Joo, S.B. Hong, (2015, Feb). Source Imaging in Partial Epilepsy in Comparison with Presurgical Evaluation and Magnetoencephalography. Journal of Clinical Neurology, 2015 Feb 17, 11:e12 (Impact Factor : 2.596; Quartile rank: Q2). . Patents . J. An, S.H. Jin, S.H. Lee, J.I. Moon B. Abibullaev, J.H. Ahn and G.H. Jang. REHABILITATION TRAINING SYSTEM AND METHOD. : 9,081,890,Washington, DC: United States. Patent and Trademark Office, 2015 (https://www.google.com/patents/US9081890). . J. An, S.H. Jin, S.H. Lee, J.I. Moon B. Abibullaev, J.H. Ahn and G.H. Jang. Self-directed rehabilitation training method combining brain signals and functional electro-stimulation. : 17077057, Application number: 14049302, 09-OCT-2013, United States, (http://www.google.com/patents/US20140200632). .",
          "url": "https://berdakh.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://berdakh.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}